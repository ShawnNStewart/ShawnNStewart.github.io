[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "I am the Assistant Director for Data Analysis at the University of Texas at Dallas International Center, and I am completing my MS in Social Data Analytics and Research in spring 2023. I am passionate about using data to solve problems and generate new insights to guide decision making."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am the Assistant Director for Data Analysis at the University of Texas at Dallas International Center, and I am completing my MS in Social Data Analytics and Research in spring 2023. I am passionate about using data to solve problems and generate new insights to guide decision making."
  },
  {
    "objectID": "Assignments.html",
    "href": "Assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "Exploratory Analysis of TEDS-2016 data - Assignment 2\n\n\n\nEPPS 6323\n\n\nassignment\n\n\n\nRun an exploratory data analysis with R using the TEDS2016 dataset.\n\n\n\nShawn Stewart\n\n\nFeb 15, 2023\n\n\n\n\n\n\n\n\n\n\n\nCombining tools for better data science - Assignment 1\n\n\n\nEPPS 6323\n\n\nassignment\n\n\n\nThis review explores perspectives from Breiman and Schmueli on the differences and uses for traditional statistical modeling (ie, regression) and newer predictive modeling…\n\n\n\nShawn Stewart\n\n\nFeb 19, 2023\n\n\n\n\n\n\n\n\n\n\n\nR Programming Basic Commands - Lab 2\n\n\n\nEPPS 6323\n\n\nlab\n\n\n\nLab materials provided by Dr. Ho in class.\n\n\n\nKarl Ho\n\n\n\n\n\n\n\n\n\n\n\nExploratory Data Analaysis - Lab 3\n\n\n\nEPPS 6323\n\n\nlab\n\n\n\n\n\n\n\nShawn Stewart\n\n\n\n\n\n\n\n\n\n\n\nRegression Analysis with TEDS 2016 data - Assignment 3\n\n\n\nEPPS 6323\n\n\nassignment\n\n\n\n\n\n\n\nShawn Stewart\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to R - Lab 1\n\n\n\nEPPS 6323\n\n\nlab\n\n\n\nLab materials provided by Dr. Ho in class.\n\n\n\nKarl Ho\n\n\n\n\n\n\n\n\n\n\n\nK-means Clustering - Assignment 4\n\n\n\nEPPS 6323\n\n\nassignment\n\n\n\n\n\n\n\nShawn Stewart\n\n\n\n\n\n\n\n\n\n\n\nPrinciple Component Analysis\n\n\n\nEPPS 6323\n\n\nlab\n\n\n\n\n\n\n\nShawn Stewart\n\n\n\n\n\n\n\n\n\n\n\nText Mining and Word Clouds - Assignment 5\n\n\n\nEPPS 6323\n\n\nassignment\n\n\n\nGenerating a word cloud based on famouse speeches.\n\n\n\nShawn Stewart\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/EPPS6323_Assignment1.html",
    "href": "posts/EPPS6323_Assignment1.html",
    "title": "Combining tools for better data science",
    "section": "",
    "text": "In his incisive 2001 article on the “two cultures” of statistical modeling, Breiman noted the almost exclusive use of traditional statistical techniques (ie, linear regression models) in research at the time and then details all the issues he sees with using linear models (and especially, using them exclusively). He asserts that the assumptions we must make when using linear models are not tenable and the methods we have for testing the validity of linear models are insufficient. Breiman sees algorithmic predictive models as the superior approach, and admonishes fellows in his field to move towards predictive modeling.\nIn Schmueli’s 2010 article on the difference between explanatory models and predictive models, it seems not a lot has changed in terms of statisticians’ preferences for modeling. Schmueli also comments on how regression models are used almost exclusively, to the detriment of the research. However, he advocates for combining the two - gettings the best of both worlds. He stresses that explanatory and predictive models have different uses, different strengths, and should be used in different circumstances. Often, they can work together to provide a more complete picture than either one could alone. For example, with the explosion in both the volume and type of data in recent years, predictive models can help uncover new trends and associations that we might not be able to uncover simply through reviewing the theory, literature, and running regression models. The insights we gain from predictive modelling can then feed into explanatory models.\nSchmueli also advocates for more inter-disciplinary collaborations. As both he and Breiman point out, predictive modeling is more often found in the domain of computer scientists, and statisticians and social science researchers often do not venture into this domain. All parties could improve their research and find value in cross-domain collaborations.\nReferences Breiman, L. (2001). Statistical modeling: The two cultures (with comments and a rejoinder by the author). Statistical science, 16(3), 199-231.\nShmueli, G. (2010). To explain or to predict?."
  },
  {
    "objectID": "Projects.html",
    "href": "Projects.html",
    "title": "Projects",
    "section": "",
    "text": "Project for EPPS 6356 - Data Visualization. For this project, I used the TransPop dataset (downloaded from ICPSR). I used the survey and srvyr packages to work with weighted data and developed visualizations using ggplot2.\n\n\n\nProject for EPPS 6316 - Regression Analysis. In this course, we were tasked with finding a study and replicating its results using R, then extending the study with our own regression analysis. I replicated Burford et al’s study Associations of Urbanicity and Sociodemographic Characteristics with Protective Health Behaviors and Reasons for Leaving the Home During COVID-19. You can download my dataset and R script."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\nUniversity of Texas at Dallas | Richardson, TX BA Literary Studies | December 2010\nUniversity of Texas at Dallas | Richardson, TX MS Social Data Analytics and Research | May 2023"
  },
  {
    "objectID": "posts/Lab02.html",
    "href": "posts/Lab02.html",
    "title": "R Programming Basic Commands - Lab 2",
    "section": "",
    "text": "(Adapted from ISLR Chapter 3 Lab: Introduction to R)\n\n\n\nA=matrix(1:16,4,4)\nA\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n[3,]    3    7   11   15\n[4,]    4    8   12   16\n\nA[2,3]\n\n[1] 10\n\nA[c(1,3),c(2,4)]\n\n     [,1] [,2]\n[1,]    5   13\n[2,]    7   15\n\nA[1:3,2:4]\n\n     [,1] [,2] [,3]\n[1,]    5    9   13\n[2,]    6   10   14\n[3,]    7   11   15\n\nA[1:2,]\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n\nA[,1:2]\n\n     [,1] [,2]\n[1,]    1    5\n[2,]    2    6\n[3,]    3    7\n[4,]    4    8\n\nA[1,]\n\n[1]  1  5  9 13\n\nA[-c(1,3),]\n\n     [,1] [,2] [,3] [,4]\n[1,]    2    6   10   14\n[2,]    4    8   12   16\n\nA[-c(1,3),-c(1,3,4)]\n\n[1] 6 8\n\ndim(A)\n\n[1] 4 4\n\n\n\n\n\n\nAuto=read.table(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.data\")\n# fix(Auto) # Starting the X11 R data editor\nAuto=read.table(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.data\",header=T,na.strings=\"?\")\n# fix(Auto)\nAuto=read.csv(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.csv\",header=T,na.strings=\"?\")\n# fix(Auto)\ndim(Auto)\n\n[1] 397   9\n\nAuto[1:4,]\n\n  mpg cylinders displacement horsepower weight acceleration year origin\n1  18         8          307        130   3504         12.0   70      1\n2  15         8          350        165   3693         11.5   70      1\n3  18         8          318        150   3436         11.0   70      1\n4  16         8          304        150   3433         12.0   70      1\n                       name\n1 chevrolet chevelle malibu\n2         buick skylark 320\n3        plymouth satellite\n4             amc rebel sst\n\nAuto=na.omit(Auto)\ndim(Auto)\n\n[1] 392   9\n\nnames(Auto)\n\n[1] \"mpg\"          \"cylinders\"    \"displacement\" \"horsepower\"   \"weight\"      \n[6] \"acceleration\" \"year\"         \"origin\"       \"name\"        \n\n\n\n\n\n\nAuto=read.table(\"https://www.statlearning.com/s/Auto.data\",header=T,na.strings=\"?\")\ndim(Auto)\n\n[1] 397   9\n\n\n\n\n\n\n# plot(cylinders, mpg)\nplot(Auto$cylinders, Auto$mpg)\n\n\n\nattach(Auto)\nplot(cylinders, mpg)\n\n\n\ncylinders=as.factor(cylinders)\nplot(cylinders, mpg)\n\n\n\nplot(cylinders, mpg, col=\"red\")\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T)\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T,horizontal=T)\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T, xlab=\"cylinders\", ylab=\"MPG\")\n\n\n\nhist(mpg)\n\n\n\nhist(mpg,col=2)\n\n\n\nhist(mpg,col=2,breaks=15)\n\n\n\n#pairs(Auto)\npairs(~ mpg + displacement + horsepower + weight + acceleration, Auto)\n\n\n\nplot(horsepower,mpg)\n\n\n\n# identify(horsepower,mpg,name) # Interactive: point and click the dot to identify cases\nsummary(Auto)\n\n      mpg          cylinders      displacement     horsepower        weight    \n Min.   : 9.00   Min.   :3.000   Min.   : 68.0   Min.   : 46.0   Min.   :1613  \n 1st Qu.:17.50   1st Qu.:4.000   1st Qu.:104.0   1st Qu.: 75.0   1st Qu.:2223  \n Median :23.00   Median :4.000   Median :146.0   Median : 93.5   Median :2800  \n Mean   :23.52   Mean   :5.458   Mean   :193.5   Mean   :104.5   Mean   :2970  \n 3rd Qu.:29.00   3rd Qu.:8.000   3rd Qu.:262.0   3rd Qu.:126.0   3rd Qu.:3609  \n Max.   :46.60   Max.   :8.000   Max.   :455.0   Max.   :230.0   Max.   :5140  \n                                                 NA's   :5                     \n  acceleration        year           origin          name          \n Min.   : 8.00   Min.   :70.00   Min.   :1.000   Length:397        \n 1st Qu.:13.80   1st Qu.:73.00   1st Qu.:1.000   Class :character  \n Median :15.50   Median :76.00   Median :1.000   Mode  :character  \n Mean   :15.56   Mean   :75.99   Mean   :1.574                     \n 3rd Qu.:17.10   3rd Qu.:79.00   3rd Qu.:2.000                     \n Max.   :24.80   Max.   :82.00   Max.   :3.000                     \n                                                                   \n\nsummary(mpg)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.00   17.50   23.00   23.52   29.00   46.60 \n\n\n\n\n\n\nptbu=c(\"MASS\",\"ISLR\")\ninstall.packages(ptbu, repos='http://cran.us.r-project.org')\n\n\nThe downloaded binary packages are in\n    /var/folders/lp/fy668bhn4jvcgy6x11n3_h4m0000gn/T//RtmpRc4KtC/downloaded_packages\n\nlapply(ptbu, require, character.only = TRUE)\n\nLoading required package: MASS\n\n\nLoading required package: ISLR\n\n\n\nAttaching package: 'ISLR'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    Auto\n\n\n[[1]]\n[1] TRUE\n\n[[2]]\n[1] TRUE\n\nlibrary(MASS)\nlibrary(ISLR)\n\n# Simple Linear Regression\n\n# fix(Boston)\nnames(Boston)\n\n [1] \"crim\"    \"zn\"      \"indus\"   \"chas\"    \"nox\"     \"rm\"      \"age\"    \n [8] \"dis\"     \"rad\"     \"tax\"     \"ptratio\" \"black\"   \"lstat\"   \"medv\"   \n\n# lm.fit=lm(medv~lstat)\nattach(Boston)\nlm.fit=lm(medv~lstat,data=Boston)\nattach(Boston)\n\nThe following objects are masked from Boston (pos = 3):\n\n    age, black, chas, crim, dis, indus, lstat, medv, nox, ptratio, rad,\n    rm, tax, zn\n\nlm.fit=lm(medv~lstat)\nlm.fit\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nCoefficients:\n(Intercept)        lstat  \n      34.55        -0.95  \n\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.168  -3.990  -1.318   2.034  24.500 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 34.55384    0.56263   61.41   <2e-16 ***\nlstat       -0.95005    0.03873  -24.53   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.216 on 504 degrees of freedom\nMultiple R-squared:  0.5441,    Adjusted R-squared:  0.5432 \nF-statistic: 601.6 on 1 and 504 DF,  p-value: < 2.2e-16\n\nnames(lm.fit)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\ncoef(lm.fit)\n\n(Intercept)       lstat \n 34.5538409  -0.9500494 \n\nconfint(lm.fit)\n\n                2.5 %     97.5 %\n(Intercept) 33.448457 35.6592247\nlstat       -1.026148 -0.8739505\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"confidence\")\n\n       fit      lwr      upr\n1 29.80359 29.00741 30.59978\n2 25.05335 24.47413 25.63256\n3 20.30310 19.73159 20.87461\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"prediction\")\n\n       fit       lwr      upr\n1 29.80359 17.565675 42.04151\n2 25.05335 12.827626 37.27907\n3 20.30310  8.077742 32.52846\n\n# What is the differnce between \"conference\" and \"prediction\" difference?\n\nplot(lstat,medv)\nabline(lm.fit)\nabline(lm.fit,lwd=3)\nabline(lm.fit,lwd=3,col=\"red\")\n\n\n\nplot(lstat,medv,col=\"red\")\n\n\n\nplot(lstat,medv,pch=16)\n\n\n\nplot(lstat,medv,pch=\"+\")\n\n\n\nplot(1:20,1:20,pch=1:20)\n\n\n\npar(mfrow=c(2,2))\nplot(lm.fit)\n\n\n\nplot(predict(lm.fit), residuals(lm.fit))\nplot(predict(lm.fit), rstudent(lm.fit))\nplot(hatvalues(lm.fit))\nwhich.max(hatvalues(lm.fit))\n\n375 \n375 \n\n\n\n\n\n\n\n\n\nlm.fit=lm(medv~lstat+age,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat + age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.981  -3.978  -1.283   1.968  23.158 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 33.22276    0.73085  45.458  < 2e-16 ***\nlstat       -1.03207    0.04819 -21.416  < 2e-16 ***\nage          0.03454    0.01223   2.826  0.00491 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.173 on 503 degrees of freedom\nMultiple R-squared:  0.5513,    Adjusted R-squared:  0.5495 \nF-statistic:   309 on 2 and 503 DF,  p-value: < 2.2e-16\n\nlm.fit=lm(medv~.,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ ., data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.595  -2.730  -0.518   1.777  26.199 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***\ncrim        -1.080e-01  3.286e-02  -3.287 0.001087 ** \nzn           4.642e-02  1.373e-02   3.382 0.000778 ***\nindus        2.056e-02  6.150e-02   0.334 0.738288    \nchas         2.687e+00  8.616e-01   3.118 0.001925 ** \nnox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***\nrm           3.810e+00  4.179e-01   9.116  < 2e-16 ***\nage          6.922e-04  1.321e-02   0.052 0.958229    \ndis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***\nrad          3.060e-01  6.635e-02   4.613 5.07e-06 ***\ntax         -1.233e-02  3.760e-03  -3.280 0.001112 ** \nptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***\nblack        9.312e-03  2.686e-03   3.467 0.000573 ***\nlstat       -5.248e-01  5.072e-02 -10.347  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.745 on 492 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7338 \nF-statistic: 108.1 on 13 and 492 DF,  p-value: < 2.2e-16\n\nlibrary(car)\n\nLoading required package: carData\n\nvif(lm.fit)\n\n    crim       zn    indus     chas      nox       rm      age      dis \n1.792192 2.298758 3.991596 1.073995 4.393720 1.933744 3.100826 3.955945 \n     rad      tax  ptratio    black    lstat \n7.484496 9.008554 1.799084 1.348521 2.941491 \n\nlm.fit1=lm(medv~.-age,data=Boston)\nsummary(lm.fit1)\n\n\nCall:\nlm(formula = medv ~ . - age, data = Boston)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.6054  -2.7313  -0.5188   1.7601  26.2243 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  36.436927   5.080119   7.172 2.72e-12 ***\ncrim         -0.108006   0.032832  -3.290 0.001075 ** \nzn            0.046334   0.013613   3.404 0.000719 ***\nindus         0.020562   0.061433   0.335 0.737989    \nchas          2.689026   0.859598   3.128 0.001863 ** \nnox         -17.713540   3.679308  -4.814 1.97e-06 ***\nrm            3.814394   0.408480   9.338  < 2e-16 ***\ndis          -1.478612   0.190611  -7.757 5.03e-14 ***\nrad           0.305786   0.066089   4.627 4.75e-06 ***\ntax          -0.012329   0.003755  -3.283 0.001099 ** \nptratio      -0.952211   0.130294  -7.308 1.10e-12 ***\nblack         0.009321   0.002678   3.481 0.000544 ***\nlstat        -0.523852   0.047625 -10.999  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.74 on 493 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7343 \nF-statistic: 117.3 on 12 and 493 DF,  p-value: < 2.2e-16\n\nlm.fit1=update(lm.fit, ~.-age)\n\n\n\n\n\nlm.fit2=lm(medv~lstat+I(lstat^2))\nsummary(lm.fit2)\n\n\nCall:\nlm(formula = medv ~ lstat + I(lstat^2))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.2834  -3.8313  -0.5295   2.3095  25.4148 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 42.862007   0.872084   49.15   <2e-16 ***\nlstat       -2.332821   0.123803  -18.84   <2e-16 ***\nI(lstat^2)   0.043547   0.003745   11.63   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.524 on 503 degrees of freedom\nMultiple R-squared:  0.6407,    Adjusted R-squared:  0.6393 \nF-statistic: 448.5 on 2 and 503 DF,  p-value: < 2.2e-16\n\nlm.fit=lm(medv~lstat)\nanova(lm.fit,lm.fit2)\n\nAnalysis of Variance Table\n\nModel 1: medv ~ lstat\nModel 2: medv ~ lstat + I(lstat^2)\n  Res.Df   RSS Df Sum of Sq     F    Pr(>F)    \n1    504 19472                                 \n2    503 15347  1    4125.1 135.2 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\npar(mfrow=c(2,2))\nplot(lm.fit2)\n\n\n\nlm.fit5=lm(medv~poly(lstat,5))\nsummary(lm.fit5)\n\n\nCall:\nlm(formula = medv ~ poly(lstat, 5))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.5433  -3.1039  -0.7052   2.0844  27.1153 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)       22.5328     0.2318  97.197  < 2e-16 ***\npoly(lstat, 5)1 -152.4595     5.2148 -29.236  < 2e-16 ***\npoly(lstat, 5)2   64.2272     5.2148  12.316  < 2e-16 ***\npoly(lstat, 5)3  -27.0511     5.2148  -5.187 3.10e-07 ***\npoly(lstat, 5)4   25.4517     5.2148   4.881 1.42e-06 ***\npoly(lstat, 5)5  -19.2524     5.2148  -3.692 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.215 on 500 degrees of freedom\nMultiple R-squared:  0.6817,    Adjusted R-squared:  0.6785 \nF-statistic: 214.2 on 5 and 500 DF,  p-value: < 2.2e-16\n\nsummary(lm(medv~log(rm),data=Boston))\n\n\nCall:\nlm(formula = medv ~ log(rm), data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.487  -2.875  -0.104   2.837  39.816 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -76.488      5.028  -15.21   <2e-16 ***\nlog(rm)       54.055      2.739   19.73   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.915 on 504 degrees of freedom\nMultiple R-squared:  0.4358,    Adjusted R-squared:  0.4347 \nF-statistic: 389.3 on 1 and 504 DF,  p-value: < 2.2e-16\n\n\n\n\n\n\n# fix(Carseats)\nnames(Carseats)\n\n [1] \"Sales\"       \"CompPrice\"   \"Income\"      \"Advertising\" \"Population\" \n [6] \"Price\"       \"ShelveLoc\"   \"Age\"         \"Education\"   \"Urban\"      \n[11] \"US\"         \n\nlm.fit=lm(Sales~.+Income:Advertising+Price:Age,data=Carseats)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = Sales ~ . + Income:Advertising + Price:Age, data = Carseats)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9208 -0.7503  0.0177  0.6754  3.3413 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         6.5755654  1.0087470   6.519 2.22e-10 ***\nCompPrice           0.0929371  0.0041183  22.567  < 2e-16 ***\nIncome              0.0108940  0.0026044   4.183 3.57e-05 ***\nAdvertising         0.0702462  0.0226091   3.107 0.002030 ** \nPopulation          0.0001592  0.0003679   0.433 0.665330    \nPrice              -0.1008064  0.0074399 -13.549  < 2e-16 ***\nShelveLocGood       4.8486762  0.1528378  31.724  < 2e-16 ***\nShelveLocMedium     1.9532620  0.1257682  15.531  < 2e-16 ***\nAge                -0.0579466  0.0159506  -3.633 0.000318 ***\nEducation          -0.0208525  0.0196131  -1.063 0.288361    \nUrbanYes            0.1401597  0.1124019   1.247 0.213171    \nUSYes              -0.1575571  0.1489234  -1.058 0.290729    \nIncome:Advertising  0.0007510  0.0002784   2.698 0.007290 ** \nPrice:Age           0.0001068  0.0001333   0.801 0.423812    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.011 on 386 degrees of freedom\nMultiple R-squared:  0.8761,    Adjusted R-squared:  0.8719 \nF-statistic:   210 on 13 and 386 DF,  p-value: < 2.2e-16\n\nattach(Carseats)\ncontrasts(ShelveLoc)\n\n       Good Medium\nBad       0      0\nGood      1      0\nMedium    0      1\n\n\n\n\n\n\nsummary(lm(medv~lstat*age,data=Boston))\n\n\nCall:\nlm(formula = medv ~ lstat * age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.806  -4.045  -1.333   2.085  27.552 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 36.0885359  1.4698355  24.553  < 2e-16 ***\nlstat       -1.3921168  0.1674555  -8.313 8.78e-16 ***\nage         -0.0007209  0.0198792  -0.036   0.9711    \nlstat:age    0.0041560  0.0018518   2.244   0.0252 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.149 on 502 degrees of freedom\nMultiple R-squared:  0.5557,    Adjusted R-squared:  0.5531 \nF-statistic: 209.3 on 3 and 502 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "posts/Lab01.html",
    "href": "posts/Lab01.html",
    "title": "Introduction to R - Lab 1",
    "section": "",
    "text": "x <- c(1,3,2,5)\nx\n\n[1] 1 3 2 5\n\nx = c(1,6,2)\nx\n\n[1] 1 6 2\n\ny = c(1,4,3)\n\n\n\n\n\nlength(x)  # What does length() do?\n\n[1] 3\n\nlength(y)\n\n[1] 3\n\n\n\n\n\n\nx+y\n\n[1]  2 10  5\n\nls() # List objects in the environment\n\n[1] \"x\" \"y\"\n\nrm(x,y) # Remove objects\nls()\n\ncharacter(0)\n\nrm(list=ls()) # Danger! What does this do?  Not recommended!\n\n\n\n\n\n?matrix\nx=matrix(data=c(1,2,3,4), nrow=2, ncol=2) # Create a 2x2 matrix object\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx=matrix(c(1,2,3,4),2,2)\nmatrix(c(1,2,3,4),2,2,byrow=TRUE) # What about byrow=F?\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n\nsqrt(x) # What does x look like?\n\n         [,1]     [,2]\n[1,] 1.000000 1.732051\n[2,] 1.414214 2.000000\n\nx^2\n\n     [,1] [,2]\n[1,]    1    9\n[2,]    4   16\n\nx=rnorm(50) # Generate a vector of 50 numbers using the rnorm() function\n\ny=x+rnorm(50,mean=50,sd=.1) # What does rnorm(50,mean=50,sd=.1) generate?\n\ncor(x,y) # Correlation of x and y\n\n[1] 0.9966242\n\nset.seed(1303) # Set the seed for Random Number Generator (RNG) to generate values that are reproducible.\nrnorm(50)\n\n [1] -1.1439763145  1.3421293656  2.1853904757  0.5363925179  0.0631929665\n [6]  0.5022344825 -0.0004167247  0.5658198405 -0.5725226890 -1.1102250073\n[11] -0.0486871234 -0.6956562176  0.8289174803  0.2066528551 -0.2356745091\n[16] -0.5563104914 -0.3647543571  0.8623550343 -0.6307715354  0.3136021252\n[21] -0.9314953177  0.8238676185  0.5233707021  0.7069214120  0.4202043256\n[26] -0.2690521547 -1.5103172999 -0.6902124766 -0.1434719524 -1.0135274099\n[31]  1.5732737361  0.0127465055  0.8726470499  0.4220661905 -0.0188157917\n[36]  2.6157489689 -0.6931401748 -0.2663217810 -0.7206364412  1.3677342065\n[41]  0.2640073322  0.6321868074 -1.3306509858  0.0268888182  1.0406363208\n[46]  1.3120237985 -0.0300020767 -0.2500257125  0.0234144857  1.6598706557\n\nset.seed(3) # Try different seeds?\ny=rnorm(100)\n\n\n\n\n\nmean(y)\n\n[1] 0.01103557\n\nvar(y)\n\n[1] 0.7328675\n\nsqrt(var(y))\n\n[1] 0.8560768\n\nsd(y)\n\n[1] 0.8560768\n\n\n\n\n\n\nx=rnorm(100)\ny=rnorm(100)\nplot(x,y, pch=, col = \"steelblue\") # Scatterplot for two numeric variables by default\n\n\n\nplot(x,y, pch=20, col = \"red\",xlab=\"this is the x-axis\",ylab=\"this is the y-axis\",main=\"Plot of X vs Y\") # Add labels\n\n\n\npdf(\"Figure01.pdf\") # Save as pdf, add a path or it will be stored on the project directory\nplot(x,y,pch=20, col=\"forestgreen\") # Try different colors?\ndev.off() # Close the file using the dev.off function\n\nquartz_off_screen \n                2 \n\nx=seq(1,10) # Same as x=c(1:10)\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=1:10\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=seq(-pi,pi,length=50)\ny=x"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\nUniversity of Texas at Dallas | Richardson, TX BA Literary Studies | December 2010\nUniversity of Texas at Dallas | Richardson, TX MS Social Data Analytics and Research | May 2023"
  },
  {
    "objectID": "projects/InteractiveMap.html",
    "href": "projects/InteractiveMap.html",
    "title": "Interactive Map Generator",
    "section": "",
    "text": "For my fall 2022 Python Programming course (EPPS 6317), we were tasked with creating a tool using what we had learned about Python. The goal was to create a reusable script. For my project, I created a script in Jupyter Notebook that could be used to take a file input, generate an interactive map, and allow the user to name and save it as an HTML file to be included on the ISSO website. For more details, see the readme file.\n\nInteractive Map\nUpdated 12/10/2022 Author: Shawn Stewart\nEvery year after fall census day, we use the OSPA report to update our fact sheets, data for Open Doors, and other resources. We will use this same data to update our interactive map on our website. This program will take the OSPA data, process it, and generate an HTML map that can be embedded on the ISSO webpage.\nFirst, get the OSPA data in CSV format and save it to your computer.\nThen, run each cell below by typing “shift + enter” and enter information as prompted. It is important to run the cells in order.\nYou will be asked to select a file (the csv OSPA report you just saved) and enter a name for your final output, as well as a directory to save it in.\n\nImport modules\nThis cell sets up the libraries required to run the code. Press “shift + enter” to continue.\nimport geopandas\n#import fiona\nimport folium \nfrom folium.plugins import MarkerCluster\nimport pandas as pd\nimport geopandas as gpd\nimport requests\nimport json\nimport tkinter as tk\nfrom tkinter import filedialog\n# include this, otherwise an empty box will remain on screen after selecting file\nroot = tk.Tk()\nroot.withdraw()\nimport re\nimport os\n%matplotlib inline\n\n\nFile input\n# prompt user to select file, limited to only csv files\nfile = filedialog.askopenfilename(filetypes=[(\"csv files\", \"*.csv\")])\n\n\nRead in the data\n# check that the user entered a file. If not, prompt again.\nwhile not file:\n    print(\"You must choose a file to continue\")\n    file = filedialog.askopenfilename(filetypes=[(\"csv files\", \"*.csv\")])\n# read in the data\ndf = pd.read_csv(file)\n# keep only the columns we care about, and keep only records for F visas.\ndf = (df[[\"COUNTRY_DESC_PS\", \"GENDER\", \n          \"ACAD_PROG\", \"ACAD_GROUP\", \n          \"ACAD_PLAN_DESC\", \"OPT\", \"VISA_CATEGORY\"]]\n      .loc[df.VISA_CATEGORY == \"F\"])\n# get list of unique countries to pass to API\ncountry_list = set(df[\"COUNTRY_DESC_PS\"])\n\n\nGet longitude/latitude from Nominatim API\nThis can take a few minutes. If there is an asterisk next to the code block, it’s running.\nSee the Nominatim API documentation for more details on how the search query is structured - https://nominatim.org/release-docs/develop/api/Search/\n# create new data frame with long/lat for each country using Nominatim API\n# set base URL\nbase_url = \"https://nominatim.openstreetmap.org/search\"\n\n# create country dictionary\ncountry_list_dicts = []\n\n# run through each country, getting long/lat for each\nfor country in country_list:\n    # set search parameters\n    search_params = {\"country\": country,\n                     \"format\": \"json\",\n                     # Nominatim requires an email to track usage.\n                     \"email\": \"ICTechTeam@utdallas.edu\"}\n    # make request\n    r = requests.get(base_url, params=search_params)\n    response_text = r.text\n    data = json.loads(response_text)\n\n    try:\n       # create a new dictionary for that country\n        dict = {\"COUNTRY_DESC_PS\": country,\n                \"longitude\": data[0][\"lon\"],\n                \"latitude\": data[0][\"lat\"]}\n        # add it to list of dictionaries\n        country_list_dicts.append(dict)\n\n    except:\n        pass\n    \n# turn the list of dictionaries into a pandas dataframe\ncountries = pd.DataFrame(country_list_dicts)\n\n# merge with dataframe with all student information\ndf_geo = pd.merge(df, countries, on=\"COUNTRY_DESC_PS\")\n\n\nCreate the map\n# generate a map that shows the whole world.\nm = folium.Map(location=[20, 0], zoom_start=1.5, tiles=\"OpenStreetMap\")\n# add our data to the map as points\nfor i in range(0,len(countries)):\n        # set variable to check that country matches\n        match_country = (df[\"COUNTRY_DESC_PS\"] == countries.loc[i][\"COUNTRY_DESC_PS\"])\n        # set all your variables\n        lat = countries.loc[i]['latitude']\n        long = countries.loc[i]['longitude']\n        # create summmaries from main dataframe, counts of different categories\n        # note, pep8 says lines too long, but leaving as is\n        total = int(df[(df[\"COUNTRY_DESC_PS\"] == countries.loc[i][\"COUNTRY_DESC_PS\"])]\n                    .count()[\"COUNTRY_DESC_PS\"])\n        male = df[match_country & (df[\"GENDER\"] == \"M\")].count()[\"GENDER\"]\n        female = df[match_country & (df[\"GENDER\"] == \"F\")].count()[\"GENDER\"]\n        ugrd = df[match_country & (df[\"ACAD_PROG\"] == \"UGRD\")].count()[\"ACAD_PROG\"]\n        ms = df[match_country & (df[\"ACAD_PROG\"] == \"MASTR\")].count()[\"ACAD_PROG\"]\n        phd = df[match_country & (df[\"ACAD_PROG\"] == \"DOCT\")].count()[\"ACAD_PROG\"]\n        opt = df[match_country & (df[\"OPT\"] == \"Y\")].count()[\"OPT\"]\n        # set radius, so countries with more students get bigger circles\n        radius = 1300*(total)\n        # adjust the radius size to make the largest countries smaller\n        # otherwise they overwhelm the visualization\n        if radius > 5000000:\n            radius = 150*(total)\n        elif radius > 900000:\n            radius = 500*(total)\n        elif radius < 60000:\n            radius = 60000\n        # create hover tooltip to show country name\n        tooltip_text = countries.loc[i][\"COUNTRY_DESC_PS\"]\n        # set pop up text formatting and labels\n        popup_text = \"\"\"<h4>{}</h4><br>\n                    <b>Count</b>: {}<br><br>\n                    <b>Undergraduates</b>: {}<br>\n                    <b>Master's</b>: {}<br>\n                    <b>Doctoral</b>: {}<br><br>\n                    <b>On OPT</b>: {}<br><br>\n                    <b>Male</b>: {}<br>\n                    <b>Female</b>: {}<br>\n                    \"\"\"\n        # set pop up text variables\n        popup_text = popup_text.format(countries.iloc[i]['COUNTRY_DESC_PS'],\n                                       total,\n                                       ugrd,\n                                       ms,\n                                       phd,\n                                       opt,\n                                       male,\n                                       female)\n        # generate the circle markers, populating with variables set in loop\n        folium.Circle(location=[lat, long],\n                      radius=radius,\n                      tooltip=tooltip_text,\n                      popup=popup_text,\n                      fill=True).add_to(m)\n# preview the map here\nm\n\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n\nSave the file\nRun the following code block and enter the file name and select the location where you would like to save your output file.\n# prompt user for file name and check that it is a valid file name\nfile_name = input(\"Enter file name: \")\ncheck = True\nwhile check:\n    # check that filename does not include special characters\n    if not re.match(\"[- _a-zA-Z0-9]*$\", file_name):\n        print(\"Please only enter letters, numbers, underscores, or hyphens.\")\n        file_name = input(\"Enter file name: \")\n    # check that user actually entered a filename\n    elif not file_name:\n        print(\"Please enter a filename.\")\n        file_name = input(\"Enter file name: \")\n    else:\n        check = False\n\n# prompt user for where to save the file\ndirectory = filedialog.askdirectory()\nwhile not directory:\n    print(\"You must choose a location to save your map.\")\n    directory = filedialog.askdirectory()\n# change directory to the selected directory\nos.chdir(directory)\n\n# save map to html in selected directory\nm.save(file_name+\".html\")\nEnter file name: final_test\n\n\nYou’re done!\nYou can take the resulting HTML file to add to our WordPress instance. You can find instructions on how to update WordPress in the Digital Media Assistant manual in OneNote."
  },
  {
    "objectID": "Projects.html#python",
    "href": "Projects.html#python",
    "title": "Projects",
    "section": "Python",
    "text": "Python\n\nShowcasing Diversity: Interactive Map Generator\nProject for EPPS 6317 - Python Programming. Created a reusable python script in Jupyter Notebook to take data from OSPA report and generate an interactive map showing the country of origin for the UT Dallas international student population. The map can be saved as an HTML file, to be used on the ISSO website."
  },
  {
    "objectID": "Projects.html#sql-and-postgresql",
    "href": "Projects.html#sql-and-postgresql",
    "title": "Projects",
    "section": "SQL and PostgreSQL",
    "text": "SQL and PostgreSQL\n\nTransgender Healthcare Directory Prototype\nProject for EPPS 6354 - Information Management. For this project, I built a database using PostgreSQL, compiled sample data, and built and deployed a Shiny app."
  },
  {
    "objectID": "Projects.html#research-design",
    "href": "Projects.html#research-design",
    "title": "Projects",
    "section": "Research Design",
    "text": "Research Design\n\nResearch Design: Reducing Anti-Trans Bias Among Healthcare Providers\nProject for PPPE 6310 - Research Design. For this course, we were asked to come up with a viable research design to answer a research question. I did a literature review and developed an appropriate research design to test whether doctors’ bias towards transgender patients could be mitigated through an extended training program."
  },
  {
    "objectID": "posts/Lab03.html",
    "href": "posts/Lab03.html",
    "title": "Exploratory Data Analaysis - Lab 3",
    "section": "",
    "text": "R Programming (EDA)\n(Adapted from Stackoverflow examples) (Objectives: Use plotly, reshape packages, interactive visualization)\n\nlibrary(tidyverse)\nlibrary(plotly)\ndata(iris)\nattach(iris)\n# Generate plot on three quantitative variables\niris_plot <- plot_ly(iris,\n                     x = Sepal.Length,\n                     y = Sepal.Width,\n                     z = Petal.Length,\n                     type = \"scatter3d\",\n                     mode = \"markers\",\n                     size = 0.02)\niris_plot\n\n\n\n\n# Regression object\n\npetal_lm <- lm(Petal.Length ~ 0 + Sepal.Length + Sepal.Width,\n               data = iris)\nlibrary(reshape2)\n\n#load data\n\npetal_lm <- lm(Petal.Length ~ 0 + Sepal.Length + Sepal.Width,data = iris)\n\n# Setting resolution parameter\ngraph_reso <- 0.05\n\n#Setup Axis\naxis_x <- seq(min(iris$Sepal.Length), max(iris$Sepal.Length), by = graph_reso)\naxis_y <- seq(min(iris$Sepal.Width), max(iris$Sepal.Width), by = graph_reso)\n\n# Regression surface\n# Rearranging data for plotting\npetal_lm_surface <- expand.grid(Sepal.Length = axis_x,Sepal.Width = axis_y,KEEP.OUT.ATTRS = F)\npetal_lm_surface$Petal.Length <- predict.lm(petal_lm, newdata = petal_lm_surface)\npetal_lm_surface <- acast(petal_lm_surface, Sepal.Width ~ Sepal.Length, value.var = \"Petal.Length\")\nhcolors=c(\"orange\",\"blue\",\"green\")[iris$Species]\niris_plot <- plot_ly(iris,\n                     x = ~Sepal.Length,\n                     y = ~Sepal.Width,\n                     z = ~Petal.Length,\n                     text = Species,\n                     type = \"scatter3d\",\n                     mode = \"markers\",\n                     marker = list(color = hcolors),\n                     size=0.02)\n# Add surface\niris_plot <- add_trace(p = iris_plot,\n                       z = petal_lm_surface,\n                       x = axis_x,\n                       y = axis_y,\n                       type = \"surface\",mode = \"markers\",\n                       marker = list(color = hcolors))\niris_plot\n\n\n\n\n\n\n\nRegression object\n\npetal_lm <- lm(Petal.Length ~ 0 + Sepal.Length + Sepal.Width, \n               data = iris)"
  },
  {
    "objectID": "posts/Assignment3.html",
    "href": "posts/Assignment3.html",
    "title": "Regression Analysis with TEDS 2016 data - Assignment 3",
    "section": "",
    "text": "Loading required package: pacman"
  },
  {
    "objectID": "posts/Assignment3.html#regression-with-teds-2016-data",
    "href": "posts/Assignment3.html#regression-with-teds-2016-data",
    "title": "Regression Analysis with TEDS 2016 data - Assignment 3",
    "section": "Regression with TEDS 2016 data",
    "text": "Regression with TEDS 2016 data\n\n# read in the data\nteds <- read_stata(\"https://github.com/datageneration/home/blob/master/DataProgramming/data/TEDS_2016.dta?raw=true\")"
  },
  {
    "objectID": "posts/Assignment3.html#select-only-relevant-variables",
    "href": "posts/Assignment3.html#select-only-relevant-variables",
    "title": "Regression Analysis with TEDS 2016 data - Assignment 3",
    "section": "Select only relevant variables",
    "text": "Select only relevant variables\nCreate a subset of the dataset (Tondu, female, DPP, age, income, edu, Taiwanese and Econ_worse).\n\n# add labels to Tondu variable\nteds$Tondu<-as.numeric(teds$Tondu,labels=c(\"Unification now”, “Status quo, unif. in future”, “Status quo, decide later\", \"Status quo forever\", \"Status quo, indep. in future\", \"Independence now”, “No response\"))\n\nteds <- teds %>% \n    select(Tondu, female, DPP, age, income, edu, Taiwanese, Econ_worse)"
  },
  {
    "objectID": "posts/Assignment3.html#run-a-regplot-on-the-dependent-variable",
    "href": "posts/Assignment3.html#run-a-regplot-on-the-dependent-variable",
    "title": "Regression Analysis with TEDS 2016 data - Assignment 3",
    "section": "5. Run a regplot on the dependent variable",
    "text": "5. Run a regplot on the dependent variable\nUse age, education, income\n\nlm(Tondu ~ 0 + age + edu + income, data = teds)\n\n\nCall:\nlm(formula = Tondu ~ 0 + age + edu + income, data = teds)\n\nCoefficients:\n    age      edu   income  \n0.05466  0.33706  0.03406  \n\n\nWhat is the problem? Why? (hint: how many categories in the DV?)\nSince there are multiple categories in the dependent variable, it is difficult to interpret the coefficients of the model we’ve generated.\nWhat can be done to improve prediction of the dependent variable?\nRather than a simple linear regression, a multinomial logistic regression model may work better.\n\nmultinom(Tondu ~ age + edu + income, data=teds)\n\n# weights:  35 (24 variable)\ninitial  value 3269.129050 \niter  10 value 2862.327758\niter  20 value 2719.038514\niter  30 value 2652.095289\nfinal  value 2651.908647 \nconverged\n\n\nCall:\nmultinom(formula = Tondu ~ age + edu + income, data = teds)\n\nCoefficients:\n  (Intercept)          age         edu       income\n2   -0.698701  0.015056992  0.48214997  0.087870013\n3    3.135378 -0.029543248  0.37177638  0.073352836\n4    2.155079 -0.010113129  0.23946974  0.063161195\n5    3.077561 -0.041132676  0.43822387  0.066499389\n6    4.129241 -0.046893568 -0.04872328 -0.014283116\n9    1.615135  0.008656457 -0.32097630 -0.002354623\n\nResidual Deviance: 5303.817 \nAIC: 5351.817"
  },
  {
    "objectID": "posts/Assignment-2_TEDS-2016.html",
    "href": "posts/Assignment-2_TEDS-2016.html",
    "title": "Exploratory Analysis of TEDS-2016 data - Assignment 2",
    "section": "",
    "text": "Run an exploratory data analysis with R using the TEDS2016 dataset.\n\n\nLoading required package: pacman\n\n\n\n\n\n# load the data\nteds <- read_stata(\"https://github.com/datageneration/home/blob/master/DataProgramming/data/TEDS_2016.dta?raw=true\")\n\nConverting atomic to factors. Please wait...\n\n\n\n\n\n\nhead(teds)\n\n  District Sex Age Edu Arear Career Career8 Ethnic Party PartyID Tondu Tondu3\n1      201   2   4   4     1      1       1      1    25       9     3      2\n2      201   2   2   5     1      2       3      2    25       9     5      3\n3      201   1   5   5     1      1       1      2     3       1     3      2\n4      201   1   4   2     1      4       4      1    25       9     5      3\n5      201   2   5   1     1      3       5      9    25       9     9      9\n6      201   2   5   2     1      2       7      1     6       2     4      2\n  nI2 votetsai green votetsai_nm votetsai_all Independence Unification sq\n1   3       NA     0          NA            0            0           0  1\n2  98        1     0           1            1            1           0  0\n3  98        0     0           0            0            0           0  1\n4   3       NA     0          NA            0            1           0  0\n5  98       NA     0          NA            0            0           0  0\n6  98        1     1           1            1            0           0  1\n  Taiwanese edu female whitecollar lowincome income income_nm age KMT DPP npp\n1         1   4      1           1         4    8.0         8  59   0   0   0\n2         0   5      1           1         4    7.0         7  39   0   0   0\n3         0   5      0           1         5    8.0         8  63   1   0   0\n4         1   2      0           0         4    5.0         5  55   0   0   0\n5         0   1      1           0         3    5.5        NA  76   0   0   0\n6         1   2      1           1         5    9.0         9  64   0   1   0\n  noparty pfp South north Minnan_father Mainland_father Econ_worse Inequality\n1       1   0     0     1             1               0          0          1\n2       1   0     0     1             1               0          0          1\n3       0   0     0     1             1               0          1          1\n4       1   0     0     1             1               0          1          1\n5       1   0     0     1             1               0          0          0\n6       0   0     0     1             1               0          1          1\n  inequality5 econworse5 Govt_for_public pubwelf5 Govt_dont_care highincome\n1           4          3               1        5              0          1\n2           5          3               1        5              0          1\n3           5          4               1        4              1          1\n4           5          5               0        1              1          1\n5           3          3               0        3              0         NA\n6           5          4               0        2              1          1\n  votekmt votekmt_nm Blue Green No_Party voteblue voteblue_nm votedpp_1\n1       0         NA    0     0        0        0          NA        NA\n2       0          0    0     0        0        0           0         1\n3       1          1    0     0        0        1           1         0\n4       0         NA    0     0        0        0          NA        NA\n5       0         NA    0     0        0        0          NA        NA\n6       0          0    0     0        0        0           0         1\n  votekmt_1\n1        NA\n2         0\n3         1\n4        NA\n5        NA\n6         0\n\ncolnames(teds)\n\n [1] \"District\"        \"Sex\"             \"Age\"             \"Edu\"            \n [5] \"Arear\"           \"Career\"          \"Career8\"         \"Ethnic\"         \n [9] \"Party\"           \"PartyID\"         \"Tondu\"           \"Tondu3\"         \n[13] \"nI2\"             \"votetsai\"        \"green\"           \"votetsai_nm\"    \n[17] \"votetsai_all\"    \"Independence\"    \"Unification\"     \"sq\"             \n[21] \"Taiwanese\"       \"edu\"             \"female\"          \"whitecollar\"    \n[25] \"lowincome\"       \"income\"          \"income_nm\"       \"age\"            \n[29] \"KMT\"             \"DPP\"             \"npp\"             \"noparty\"        \n[33] \"pfp\"             \"South\"           \"north\"           \"Minnan_father\"  \n[37] \"Mainland_father\" \"Econ_worse\"      \"Inequality\"      \"inequality5\"    \n[41] \"econworse5\"      \"Govt_for_public\" \"pubwelf5\"        \"Govt_dont_care\" \n[45] \"highincome\"      \"votekmt\"         \"votekmt_nm\"      \"Blue\"           \n[49] \"Green\"           \"No_Party\"        \"voteblue\"        \"voteblue_nm\"    \n[53] \"votedpp_1\"       \"votekmt_1\"      \n\n\n\n\n\n\n# Prepare the analyze the Party ID variable \n# Assign label to the values (1=KMT, 2=DPP, 3=NP, 4=PFP, 5=TSU, 6=NPP, 7=\"NA\")\n\nteds$PartyID <- factor(teds$PartyID, labels=c(\"KMT\",\"DPP\",\"NP\",\"PFP\", \"TSU\", \"NPP\",\"NA\"))\n\n# Check the variable\nattach(teds)\nhead(PartyID)\n\n[1] NA  NA  KMT NA  NA  DPP\nLevels: KMT DPP NP PFP TSU NPP NA\n\ntail(PartyID)\n\n[1] NA  NA  DPP NA  NA  NA \nLevels: KMT DPP NP PFP TSU NPP NA\n\n# Let's try doing the same with the Tondu variable\nteds$Tondu <- factor(teds$Tondu, labels = get_labels(teds$Tondu))\n\n\n\n\n\n# Run a frequency table of the Party ID variable using the descr package\nfreq(teds$PartyID)\n\n\n\n\nteds$PartyID \n      Frequency  Percent\nKMT         388  22.9586\nDPP         591  34.9704\nNP            3   0.1775\nPFP          32   1.8935\nTSU           5   0.2959\nNPP          43   2.5444\nNA          628  37.1598\nTotal      1690 100.0000\n\n# Plot the Party ID variable\nteds %>% \n  count(PartyID) %>% \n  mutate(perc = n / nrow(teds)) -> T2\nggplot(T2, aes(x = reorder(PartyID, -perc),y = perc,fill=PartyID)) +\n  geom_bar(stat = \"identity\") +\n  ylab(\"Party Support (%)\") + \n  xlab(\"Taiwan Political Parties\") +\n  theme_bw() +\n  scale_fill_manual(values=c(\"steel blue\",\"forestgreen\",\"khaki1\",\"orange\",\"goldenrod\",\"yellow\",\"grey\"))\n\n\n\n\n\n\n\nWhat problems do you encounter when working with the dataset?\nI had trouble finding the codebook. Error messages about conflicting labels. The data coming from stata has labels attached to the variables. However, I had some difficulty figuring out how to view the labels directly in R, rather than referring to a codebook or manually setting the labels. I found the sjlabeller has a function called “get_labels()” that makes this very easy for variables that have this meta information included, like the Tondu variable.\n\nget_labels(teds$Tondu)\n\n[1] \"Immediate unification\"                                             \n[2] \"Maintain the status quo,move toward unification\"                   \n[3] \"Maintain the status quo, decide either unification or independence\"\n[4] \"Maintain the status quo forever\"                                   \n[5] \"Maintain the status quo,move toward independence\"                  \n[6] \"Immediate independence\"                                            \n[7] \"Nonresponse\"                                                       \n\n\nHow to deal with missing values? In general, you can either exclude or impute missing values.\n\n\nincluding female, DPP, age, income, edu, Taiwanese and Econ_worse. What methods would you use?\nTo begin exploring the data, I like to generate some simple visualizations to see the spread of the data. These are quick, unpolished visualizations just to get an idea of what we’re working with.\nIf we want to do the same visualization for multiple variables, we can wrap it in a for loop to print out our charts quickly.\n\n# Binary variables bar charts\nvar_list <- c(\"female\", \"DPP\", \"Taiwanese\", \"Econ_worse\")\n\nfor (var in var_list) {\n    chart <- teds %>%\n        ggplot(aes(x=Tondu, y=!!sym(var)), fill=!!sym(var))+\n        geom_bar(stat=\"identity\") +\n        coord_flip() + \n        labs(title=paste(\"Tondu and \",var))\n    \n    print(chart)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n# Tondu and age\n# let's find the mean age, grouped by Tondu\n\nteds %>% \n    group_by(Tondu) %>% \n    summarize(m = mean(age)) %>%\n    ggplot(aes(x=Tondu, y=m)) + \n    geom_bar(stat = \"identity\") +\n    coord_flip()\n\n\n\n# Tondu and income\nteds %>% \n    group_by(Tondu) %>% \n    summarize(m = mean(income)) %>%\n    ggplot(aes(x=Tondu, y=m)) + \n    geom_bar(stat = \"identity\") +\n    coord_flip()\n\n\n\n# Tondu and edu\n# multiple levels of variable, no baked in labels\nteds %>% \n    ggplot(aes(x=Tondu)) +\n    geom_bar() +\n    coord_flip() +\n    facet_wrap(~Edu)\n\n\n\n# Tondu and Taiwanese\n# binary variable\nteds %>% \n    ggplot(aes(x=Tondu)) +\n    geom_bar() +\n    coord_flip() +\n    facet_wrap(~Taiwanese)\n\n\n\n# Tondu and econ-worse\n# binary variable\nteds %>% \n    ggplot(aes(x=Tondu)) +\n    geom_bar() +\n    coord_flip() +\n    facet_wrap(~Econ_worse)\n\n\n\n# Tondu and votesai variable\nteds %>% \n    ggplot(aes(x=Tondu)) +\n    geom_bar() +\n    coord_flip() +\n    facet_wrap(~votetsai)\n\n\n\n\n\n\n\nAssign labels to the variable using the following:\n\nteds$Tondu<-as.numeric(teds$Tondu,labels=c(\"Unification now”, “Status quo, unif. in future”, “Status quo, decide later\", \"Status quo forever\", \"Status quo, indep. in future\", \"Independence now”, “No response\"))\n\nCreate the table and bar chart\n\n# frequency table\n\nfreq(teds$Tondu)\n\n\n\n\nteds$Tondu \n      Frequency Percent\n1            27   1.598\n2           180  10.651\n3           546  32.308\n4           328  19.408\n5           380  22.485\n6           108   6.391\n7           121   7.160\nTotal      1690 100.000\n\n# Plot the Party ID variable\nteds %>% \n  count(Tondu) %>% \n  mutate(perc = n / nrow(teds)) -> T2\nggplot(T2, aes(x = reorder(Tondu, -perc),y = perc,fill=Tondu)) +\n  geom_bar(stat = \"identity\") +\n  ylab(\"Tondu (percentage)\") + \n  xlab(\"\") +\n  theme_bw()"
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "Project for EPPS 6356 - Data Visualization. For this project, I used the TransPop dataset (downloaded from ICPSR). I used the survey and srvyr packages to work with weighted data and developed visualizations using ggplot2.\n\n\n\nProject for EPPS 6316 - Regression Analysis. In this course, we were tasked with finding a study and replicating its results using R, then extending the study with our own regression analysis. I replicated Burford et al’s study Associations of Urbanicity and Sociodemographic Characteristics with Protective Health Behaviors and Reasons for Leaving the Home During COVID-19. You can download my dataset and R script."
  },
  {
    "objectID": "projects/index.html#python",
    "href": "projects/index.html#python",
    "title": "Projects",
    "section": "Python",
    "text": "Python\n\nShowcasing Diversity: Interactive Map Generator\nProject for EPPS 6317 - Python Programming. Created a reusable python script in Jupyter Notebook to take data from OSPA report and generate an interactive map showing the country of origin for the UT Dallas international student population. The map can be saved as an HTML file, to be used on the ISSO website."
  },
  {
    "objectID": "projects/index.html#sql-and-postgresql",
    "href": "projects/index.html#sql-and-postgresql",
    "title": "Projects",
    "section": "SQL and PostgreSQL",
    "text": "SQL and PostgreSQL\n\nTransgender Healthcare Directory Prototype\nProject for EPPS 6354 - Information Management. For this project, I built a database using PostgreSQL, compiled sample data, and built and deployed a Shiny app."
  },
  {
    "objectID": "projects/index.html#research-design",
    "href": "projects/index.html#research-design",
    "title": "Projects",
    "section": "Research Design",
    "text": "Research Design\n\nResearch Design: Reducing Anti-Trans Bias Among Healthcare Providers\nProject for PPPE 6310 - Research Design. For this course, we were asked to come up with a viable research design to answer a research question. I did a literature review and developed an appropriate research design to test whether doctors’ bias towards transgender patients could be mitigated through an extended training program."
  },
  {
    "objectID": "posts/Lab_text-mining_word-cloud.html",
    "href": "posts/Lab_text-mining_word-cloud.html",
    "title": "Lab_text-mining_word-cloud",
    "section": "",
    "text": "Loading required package: XML\n\n\nLoading required package: wordcloud\n\n\nLoading required package: RColorBrewer\n\n\nLoading required package: NLP\n\n\nLoading required package: tm\n\n\nLoading required package: quanteda\n\n\nPackage version: 3.2.4\nUnicode version: 14.0\nICU version: 70.1\n\n\nParallel computing: 8 of 8 threads used.\n\n\nSee https://quanteda.io for tutorials and examples.\n\n\n\nAttaching package: 'quanteda'\n\n\nThe following object is masked from 'package:tm':\n\n    stopwords\n\n\nThe following objects are masked from 'package:NLP':\n\n    meta, meta<-\n\n\nLoading required package: quanteda.textstats\n\n\nAll packages loaded successfully"
  },
  {
    "objectID": "posts/Lab_text-mining_word-cloud.html#example-1---martin-luther-kings-i-have-a-dream-speech",
    "href": "posts/Lab_text-mining_word-cloud.html#example-1---martin-luther-kings-i-have-a-dream-speech",
    "title": "Lab_text-mining_word-cloud",
    "section": "Example 1 - Martin Luther King’s “I Have a Dream” speech",
    "text": "Example 1 - Martin Luther King’s “I Have a Dream” speech\n\n# Download text data from website\nmlk_speech <-URLencode(\"http://www.analytictech.com/mb021/mlk.htm\")\n\n# use htmlTreeParse function to read and parse paragraphs\n\ndoc.html<- htmlTreeParse(mlk_speech, useInternal=TRUE)\nmlk <- unlist(xpathApply(doc.html, '//p', xmlValue))\n\nhead(mlk, 3)\n\n[1] \"I am happy to join with you today in what will go down in\\r\\nhistory as the greatest demonstration for freedom in the history\\r\\nof our nation. \"                                                                                                                                                                                                              \n[2] \"Five score years ago a great American in whose symbolic shadow\\r\\nwe stand today signed the Emancipation Proclamation. This\\r\\nmomentous decree came as a great beckoning light of hope to\\r\\nmillions of Negro slaves who had been seared in the flames of\\r\\nwithering injustice. It came as a joyous daybreak to end the long\\r\\nnight of their captivity. \"\n[3] \"But one hundred years later the Negro is still not free. One\\r\\nhundred years later the life of the Negro is still sadly crippled\\r\\nby the manacles of segregation and the chains of discrimination. \"                                                                                                                                                        \n\n\n\nwords.vec <- VectorSource(mlk)\n\n# Check the class of words.vec\n\nclass(words.vec)\n\n[1] \"VectorSource\" \"SimpleSource\" \"Source\"      \n\n# Create Corpus object for preprocessing\nwords.corpus <- Corpus(words.vec)\ninspect(words.corpus)\n\n<<SimpleCorpus>>\nMetadata:  corpus specific: 1, document level (indexed): 0\nContent:  documents: 26\n\n [1] I am happy to join with you today in what will go down in\\r\\nhistory as the greatest demonstration for freedom in the history\\r\\nof our nation.                                                                                                                                                                                                                                                                                                                                                   \n [2] Five score years ago a great American in whose symbolic shadow\\r\\nwe stand today signed the Emancipation Proclamation. This\\r\\nmomentous decree came as a great beckoning light of hope to\\r\\nmillions of Negro slaves who had been seared in the flames of\\r\\nwithering injustice. It came as a joyous daybreak to end the long\\r\\nnight of their captivity.                                                                                                                                     \n [3] But one hundred years later the Negro is still not free. One\\r\\nhundred years later the life of the Negro is still sadly crippled\\r\\nby the manacles of segregation and the chains of discrimination.                                                                                                                                                                                                                                                                                             \n [4] One hundred years later the Negro lives on a lonely island of\\r\\npoverty in the midst of a vast ocean of material prosperity.                                                                                                                                                                                                                                                                                                                                                                     \n [5] One hundred years later the Negro is still languishing in the\\r\\ncomers of American society and finds himself in exile in his own\\r\\nland.                                                                                                                                                                                                                                                                                                                                                        \n [6] We all have come to this hallowed spot to remind America of\\r\\nthe fierce urgency of now. Now is the time to rise from the dark\\r\\nand desolate valley of segregation to the sunlit path of racial\\r\\njustice. Now is the time to change racial injustice to the solid\\r\\nrock of brotherhood. Now is the time to make justice ring out for\\r\\nall of God's children.                                                                                                                             \n [7] There will be neither rest nor tranquility in America until\\r\\nthe Negro is granted citizenship rights.                                                                                                                                                                                                                                                                                                                                                                                           \n [8] We must forever conduct our struggle on the high plane of\\r\\ndignity and discipline. We must not allow our creative protest to\\r\\ndegenerate into physical violence. Again and again we must rise\\r\\nto the majestic heights of meeting physical force with soul\\r\\nforce.                                                                                                                                                                                                                        \n [9] And the marvelous new militarism which has engulfed the Negro\\r\\ncommunity must not lead us to a distrust of all white people, for\\r\\nmany of our white brothers have evidenced by their presence here\\r\\ntoday that they have come to realize that their destiny is part\\r\\nof our destiny.                                                                                                                                                                                                      \n[10] So even though we face the difficulties of today and tomorrow\\r\\nI still have a dream. It is a dream deeply rooted in the American\\r\\ndream.                                                                                                                                                                                                                                                                                                                                                      \n[11] I have a dream that one day this nation will rise up and live\\r\\nout the true meaning of its creed: 'We hold these truths to be\\r\\nself-evident; that all men are created equal.\"                                                                                                                                                                                                                                                                                                                 \n[12] I have a dream that one day on the red hills of Georgia the\\r\\nsons of former slaves and the sons of former slave owners will be\\r\\nable to sit together at the table of brotherhood.                                                                                                                                                                                                                                                                                                             \n[13] I have a dream that one day even the state of Mississippi, a\\r\\nstate sweltering with the heat of injustice, sweltering with the\\r\\nheat of oppression, will be transformed into an oasis of freedom\\r\\nand justice.                                                                                                                                                                                                                                                                              \n[14] I have a dream that little children will one day live in a\\r\\nnation where they will not be judged by the color of their skin\\r\\nbut by the content of their character.                                                                                                                                                                                                                                                                                                                           \n[15] I have a dream today.                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n[16] I have a dream that one day down in Alabama, with its vicious\\r\\nracists, with its Governor having his lips dripping with the\\r\\nwords of interposition and nullification, one day right there in\\r\\nAlabama little black boys and black girls will be able to join\\r\\nhands with little white boys and white girls as sisters and\\r\\nbrothers.                                                                                                                                                   \n[17] I have a dream today.                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n[18] I have a dream that one day every valley shall be exalted,\\r\\nevery hill and mountain shall be made low, the rough places\\r\\nplains, and the crooked places will be made straight, and before\\r\\nthe Lord will be revealed, and all flesh shall see it together.                                                                                                                                                                                                                                  \n[19] This is our hope. This is the faith that I go back to the\\r\\nmount with. With this faith we will be able to hew out of the\\r\\nmountain of despair a stone of hope. With this faith we will be\\r\\nable to transform the genuine discords of our nation into a\\r\\nbeautiful symphony of brotherhood. With this faith we will be\\r\\nable to work together, pray together; to struggle together, to go\\r\\nto jail together, to stand up for freedom forever, )mowing that\\r\\nwe will be free one day. \n[20] And I say to you today my friends, let freedom ring. From the\\r\\nprodigious hilltops of New Hampshire, let freedom ring. From the\\r\\nmighty mountains of New York, let freedom ring. From the mighty\\r\\nAlleghenies of Pennsylvania!                                                                                                                                                                                                                                                              \n[21] Let freedom ring from the snow capped Rockies of Colorado!                                                                                                                                                                                                                                                                                                                                                                                                                                        \n[22] Let freedom ring from the curvaceous slopes of California!                                                                                                                                                                                                                                                                                                                                                                                                                                        \n[23] But not only there; let freedom ring from the Stone Mountain\\r\\nof Georgia!                                                                                                                                                                                                                                                                                                                                                                                                                       \n[24] Let freedom ring from Lookout Mountain in Tennessee!                                                                                                                                                                                                                                                                                                                                                                                                                                              \n[25] Let freedom ring from every hill and molehill in Mississippi.\\r\\nFrom every mountainside, let freedom ring.                                                                                                                                                                                                                                                                                                                                                                                       \n[26] And when this happens, when we allow freedom to ring, when we\\r\\nlet it ring from every village and hamlet, from every state and\\r\\nevery city, we will be able to speed up that day when all of\\r\\nGod's children, black men and white men, Jews and Gentiles,\\r\\nProtestants and Catholics, will be able to join hands and sing in\\r\\nthe words of the old Negro spiritual, \"Free at last! Free at\\r\\nlast! Thank God almighty, we're free at last!\"                                            \n\n\n\n# Turn all words to lower case\nwords.corpus <- tm_map(words.corpus, content_transformer(tolower))\n\nWarning in tm_map.SimpleCorpus(words.corpus, content_transformer(tolower)):\ntransformation drops documents\n\n# Remove punctuations, numbers\nwords.corpus <- tm_map(words.corpus, removePunctuation)\n\nWarning in tm_map.SimpleCorpus(words.corpus, removePunctuation): transformation\ndrops documents\n\nwords.corpus <- tm_map(words.corpus, removeNumbers)\n\nWarning in tm_map.SimpleCorpus(words.corpus, removeNumbers): transformation\ndrops documents\n\n# How about stopwords, then uniform bag of words created\n\nwords.corpus <- tm_map(words.corpus, removeWords, stopwords(\"english\"))\n\nWarning in tm_map.SimpleCorpus(words.corpus, removeWords,\nstopwords(\"english\")): transformation drops documents\n\n# Create Term Document Matrix\ntdm <- TermDocumentMatrix(words.corpus)\ninspect(tdm)\n\n<<TermDocumentMatrix (terms: 260, documents: 26)>>\nNon-/sparse entries: 383/6377\nSparsity           : 94%\nMaximal term length: 14\nWeighting          : term frequency (tf)\nSample             :\n         Docs\nTerms     16 18 19 2 20 26 3 6 8 9\n  able     1  0  3 0  0  2 0 0 0 0\n  day      2  1  1 0  0  1 0 0 0 0\n  dream    1  1  0 0  0  0 0 0 0 0\n  every    0  2  0 0  0  3 0 0 0 0\n  freedom  0  0  1 0  3  1 0 0 0 0\n  let      0  0  0 0  3  1 0 0 0 0\n  negro    0  0  0 1  0  1 2 0 0 1\n  one      2  1  1 0  0  0 2 0 0 0\n  ring     0  0  0 0  3  2 0 1 0 0\n  today    0  0  0 1  1  0 0 0 0 1\n\n\n\nm <- as.matrix(tdm)\nwordCounts <- rowSums(m)\nwordCounts <- sort(wordCounts, decreasing=TRUE)\nhead(wordCounts)\n\nfreedom     one    ring   dream     let     day \n     13      12      12      11      10       9 \n\n\n\n# Create Wordcloud\ncloudFrame<-data.frame(word=names(wordCounts),freq=wordCounts)\n\nset.seed(1234)\nwordcloud(cloudFrame$word,cloudFrame$freq)\n\n\n\n\n\nwordcloud(names(wordCounts),wordCounts, min.freq=1,random.order=FALSE, max.words=200,scale=c(4,.5), rot.per=0.35,colors=brewer.pal(8,\"Dark2\"))\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 1, random.order\n= FALSE, : genuine could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 1, random.order\n= FALSE, : symphony could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 1, random.order\n= FALSE, : prodigious could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 1, random.order\n= FALSE, : california could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 1, random.order\n= FALSE, : curvaceous could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 1, random.order\n= FALSE, : slopes could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 1, random.order\n= FALSE, : tennessee could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 1, random.order\n= FALSE, : catholics could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 1, random.order\n= FALSE, : happens could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 1, random.order\n= FALSE, : protestants could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 1, random.order\n= FALSE, : thank could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 1, random.order\n= FALSE, : village could not be fit on page. It will not be plotted.\n\n\n\n\n\n\n#  N-gram with two to three words\ntextstat_collocations(mlk, size = 2:3) \n\n            collocation count count_nested length      lambda           z\n1               will be    12           12      2  6.18006777  8.52344174\n2          freedom ring     9            9      2  6.16204416  7.86093251\n3                i have     8            8      2  5.79950409  7.72674740\n4                have a     9            9      2  5.30708831  7.60099495\n5            dream that     6            6      2  5.58442352  7.07713450\n6           let freedom     9            9      2  7.01188170  7.02799330\n7               one day     8            8      2  6.90192349  6.87515367\n8               a dream    10           10      2  6.25575004  6.75194436\n9              that one     5            5      2  5.10594547  6.58004714\n10            ring from     6            6      2  7.73858495  6.34302115\n11              we will     5            5      2  3.86081718  6.15370386\n12             negro is     4            4      2  4.65396035  6.11597271\n13           from every     4            4      2  5.11785291  5.94481579\n14              free at     3            3      2  7.12331459  5.59608371\n15            with this     3            3      2  4.53006624  5.45220051\n16             faith we     3            3      2  5.65068819  5.36947278\n17           this faith     3            3      2  5.65068819  5.36947278\n18             from the     7            7      2  3.08341547  5.30363525\n19             must not     2            2      2  5.42620788  5.20460024\n20             is still     3            3      2  5.37989735  5.19780340\n21           our nation     2            2      2  4.97170545  5.01431149\n22        hundred years     4            4      2  8.47324130  4.98413645\n23          years later     4            4      2  8.47324130  4.98413645\n24              we must     3            3      2  5.07381420  4.97383211\n25            the negro     6            6      2  3.68934326  4.86196261\n26              when we     2            2      2  4.65902686  4.81929021\n27              at last     3            3      2  8.22318001  4.78477488\n28              be able     7            7      2  7.12435112  4.76029764\n29          dream today     2            2      2  3.86677203  4.56840706\n30             with its     2            2      2  4.93219948  4.55360715\n31       god's children     2            2      2  7.88795934  4.50342390\n32           join hands     2            2      2  7.88795934  4.50342390\n33          for freedom     2            2      2  4.22651634  4.48456912\n34              came as     2            2      2  7.37588215  4.40694725\n35          one hundred     4            4      2  6.72982407  4.39835771\n36              able to     7            7      2  6.39243238  4.32365147\n37               in the     6            6      2  2.17334653  4.23621778\n38             shall be     2            2      2  4.50299743  4.22317970\n39               of our     4            4      2  3.05434175  4.19053424\n40               now is     3            3      2  6.47977386  4.17865188\n41              this is     2            2      2  3.31514248  4.14434519\n42                 as a     2            2      2  3.79901427  4.10034493\n43           every hill     2            2      2  6.58366067  4.09636748\n44      sweltering with     2            2      2  6.58366067  4.09636748\n45            you today     2            2      2  6.58366067  4.09636748\n46            have come     2            2      2  5.93072831  3.75354799\n47             of their     3            3      2  3.11909113  3.70546496\n48            and white     2            2      2  3.07448132  3.60774987\n49               by the     3            3      2  3.54339573  3.59126502\n50               is the     4            4      2  2.19722458  3.57802740\n51              time to     3            3      2  5.44370637  3.56663099\n52              be made     2            2      2  5.60288199  3.56485743\n53              down in     2            2      2  5.53491835  3.52478998\n54           in alabama     2            2      2  5.53491835  3.52478998\n55              to join     3            3      2  5.31969109  3.48898372\n56              a great     2            2      2  5.35416110  3.41693189\n57             boys and     2            2      2  5.30023860  3.38442936\n58             hill and     2            2      2  5.30023860  3.38442936\n59            later the     4            4      2  4.91465823  3.28099274\n60              come to     2            2      2  5.06556144  3.24149604\n61              of hope     2            2      2  3.27349691  3.13681123\n62               of new     2            2      2  3.27349691  3.13681123\n63       of brotherhood     3            3      2  4.73118685  3.11387202\n64               on the     2            2      2  3.18731502  3.05651338\n65          mountain of     2            2      2  2.76134150  3.04496971\n66             the time     3            3      2  4.62239955  3.04364353\n67              heat of     2            2      2  4.37343722  2.80997063\n68            of former     2            2      2  4.37343722  2.80997063\n69           of georgia     2            2      2  4.37343722  2.80997063\n70             of god's     2            2      2  4.37343722  2.80997063\n71       of segregation     2            2      2  4.37343722  2.80997063\n72              sons of     2            2      2  4.37343722  2.80997063\n73             words of     2            2      2  4.37343722  2.80997063\n74             with the     3            3      2  1.79939863  2.76173771\n75             the heat     2            2      2  4.26669595  2.74251867\n76           the mighty     2            2      2  4.26669595  2.74251867\n77             the sons     2            2      2  4.26669595  2.74251867\n78            the words     2            2      2  4.26669595  2.74251867\n79               all of     2            2      2  2.17088994  2.70389360\n80              and the     4            4      2  1.03334279  1.93104709\n81               to the     4            4      2  0.94890804  1.78367373\n82          the time to     3            0      3  3.26606636  1.13032087\n83             i have a     8            0      3  1.68160853  0.72439251\n84               of the     4            4      2  0.34188073  0.66310057\n85           be able to     7            0      3  1.70455087  0.59024096\n86         have come to     2            0      3  1.31957164  0.45161399\n87         all of god's     2            0      3  1.15936850  0.39431642\n88          is the time     3            0      3  0.95979188  0.36001531\n89           now is the     3            0      3  0.84580085  0.31720719\n90        with the heat     2            0      3  0.76999175  0.28684695\n91         the negro is     4            0      3  0.67536052  0.28260464\n92         have a dream     9            0      3  0.58984656  0.24426851\n93        of our nation     2            0      3  0.51082562  0.21746223\n94      with this faith     3            0      3  0.56734869  0.20916795\n95      years later the     4            0      3  0.57735438  0.19339014\n96        this faith we     3            0      3  0.38052616  0.14028450\n97           we will be     5            0      3  0.09967316  0.04495999\n98        faith we will     3            0      3 -0.07503519 -0.03083945\n99  sweltering with the     2            0      3 -0.23655401 -0.08710125\n100   of god's children     2            0      3 -0.28259670 -0.09369478\n101           came as a     2            0      3 -0.47356870 -0.15911139\n102      negro is still     3            0      3 -0.65642674 -0.26710716\n103         the heat of     2            0      3 -0.72619021 -0.28440540\n104         the sons of     2            0      3 -0.72619021 -0.28440540\n105        the words of     2            0      3 -0.72619021 -0.28440540\n106      sons of former     2            0      3 -1.04380405 -0.32331979\n107      dream that one     5            0      3 -0.85247922 -0.34520461\n108     from the mighty     2            0      3 -1.05164841 -0.40368538\n109   one hundred years     4            0      3 -1.25663553 -0.41832975\n110        a dream that     6            0      3 -1.38415532 -0.53242854\n111    let freedom ring     9            0      3 -1.60239563 -0.58922893\n112        that one day     5            0      3 -1.56115267 -0.63470415\n113   freedom ring from     5            0      3 -1.81950938 -0.71538178\n114     later the negro     3            0      3 -2.15475846 -0.90562482\n115       to join hands     2            0      3 -2.79512694 -0.92620311\n116        will be able     7            0      3 -2.54461097 -0.97862289\n117        free at last     3            0      3 -3.12717816 -1.00821968\n118      every hill and     2            0      3 -2.78472739 -1.01433624\n119       a dream today     2            0      3 -2.89970755 -1.11102196\n120       ring from the     3            0      3 -2.71402483 -1.11463644\n121 hundred years later     4            0      3 -3.97447602 -1.20437115\n122     ring from every     2            0      3 -4.04445379 -1.60411403\n123        able to join     2            0      3 -5.51680143 -2.04130446"
  },
  {
    "objectID": "posts/Lab_text-mining_word-cloud.html#example-2---winston-churchills-finest-hour-speech",
    "href": "posts/Lab_text-mining_word-cloud.html#example-2---winston-churchills-finest-hour-speech",
    "title": "Lab_text-mining_word-cloud",
    "section": "Example 2 - Winston Churchill’s “Finest Hour” speech",
    "text": "Example 2 - Winston Churchill’s “Finest Hour” speech\n\n# load the speech text\nwc_speech <-URLencode(\"http://www.historyplace.com/speeches/churchill-hour.htm\")\n\n# use htmlTreeParse function to read and parse paragraphs\ndoc.html<- htmlTreeParse(wc_speech, useInternal=TRUE)\nwc <- unlist(xpathApply(doc.html, '//p', xmlValue))\nhead(wc, 3)\n\n[1] \"\"                                                                                                                                                                                                                                                                                                        \n[2] \"\"                                                                                                                                                                                                                                                                                                        \n[3] \"\\n        At 5:30 a.m. on May 10, 1940, Nazi Germany began a massive attack against\\n        Holland, Belgium, Luxembourg, and France. Defending those countries were\\n        soldiers of the British Expeditionary Force  along with the French, Belgian,\\n        and Dutch (Allied) armies. \\n      \"\n\nwords.vec <- VectorSource(wc)\n\n\n# Turn all words to lower case\nwords.corpus <- tm_map(words.corpus, content_transformer(tolower))\n\nWarning in tm_map.SimpleCorpus(words.corpus, content_transformer(tolower)):\ntransformation drops documents\n\n# Remove punctuations, numbers\nwords.corpus <- tm_map(words.corpus, removePunctuation)\n\nWarning in tm_map.SimpleCorpus(words.corpus, removePunctuation): transformation\ndrops documents\n\nwords.corpus <- tm_map(words.corpus, removeNumbers)\n\nWarning in tm_map.SimpleCorpus(words.corpus, removeNumbers): transformation\ndrops documents\n\n# How about stopwords, then uniform bag of words created\nwords.corpus <- tm_map(words.corpus, removeWords, stopwords(\"english\"))\n\nWarning in tm_map.SimpleCorpus(words.corpus, removeWords,\nstopwords(\"english\")): transformation drops documents\n\n\n\n# Create Term Document Matric\ntdm <- TermDocumentMatrix(words.corpus)\ninspect(tdm)\n\n<<TermDocumentMatrix (terms: 260, documents: 26)>>\nNon-/sparse entries: 383/6377\nSparsity           : 94%\nMaximal term length: 14\nWeighting          : term frequency (tf)\nSample             :\n         Docs\nTerms     16 18 19 2 20 26 3 6 8 9\n  able     1  0  3 0  0  2 0 0 0 0\n  day      2  1  1 0  0  1 0 0 0 0\n  dream    1  1  0 0  0  0 0 0 0 0\n  every    0  2  0 0  0  3 0 0 0 0\n  freedom  0  0  1 0  3  1 0 0 0 0\n  let      0  0  0 0  3  1 0 0 0 0\n  negro    0  0  0 1  0  1 2 0 0 1\n  one      2  1  1 0  0  0 2 0 0 0\n  ring     0  0  0 0  3  2 0 1 0 0\n  today    0  0  0 1  1  0 0 0 0 1\n\n\n\nm <- as.matrix(tdm)\nwordCounts <- rowSums(m)\nwordCounts <- sort(wordCounts, decreasing=TRUE)\nhead(wordCounts)\n\nfreedom     one    ring   dream     let     day \n     13      12      12      11      10       9 \n\n\n\n# Create Wordcloud\ncloudFrame<-data.frame(word=names(wordCounts),freq=wordCounts)\n\n\nset.seed(1234)\nwordcloud(cloudFrame$word,cloudFrame$freq)\n\n\n\nwordcloud(names(wordCounts),wordCounts, min.freq=1,random.order=FALSE, max.words=200,scale=c(4,.5), rot.per=0.35,colors=brewer.pal(8,\"Dark2\"))\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 1, random.order\n= FALSE, : genuine could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 1, random.order\n= FALSE, : symphony could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 1, random.order\n= FALSE, : prodigious could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 1, random.order\n= FALSE, : california could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 1, random.order\n= FALSE, : curvaceous could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 1, random.order\n= FALSE, : slopes could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 1, random.order\n= FALSE, : tennessee could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 1, random.order\n= FALSE, : catholics could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 1, random.order\n= FALSE, : happens could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 1, random.order\n= FALSE, : protestants could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 1, random.order\n= FALSE, : thank could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 1, random.order\n= FALSE, : village could not be fit on page. It will not be plotted.\n\n\n\n\n\n\n#  N-gram with two to three words\ntextstat_collocations(wc, size = 2:3) \n\n                    collocation count count_nested length      lambda\n1                       we have    28           26      2  3.77916262\n2                     air force     7            7      2  5.54649978\n3                     in france    15           14      2  4.81291927\n4                       will be     9            9      2  3.69621960\n5                        of the    44           44      2  1.63072006\n6                        in the    33           33      2  1.84498145\n7                        a very     8            8      2  4.28352659\n8                        do not     6            6      2  5.47343255\n9                     have been     8            8      2  4.10384854\n10                history place     4            4      2  7.23311404\n11                     would be     6            6      2  4.23618394\n12                    there are     5            5      2  4.79507728\n13                   very large     4            4      2  4.97349698\n14                    before us     3            3      2  6.08314863\n15                    they were     5            5      2  4.00447706\n16                     last war     4            4      2  5.27775864\n17                       it has     5            5      2  4.38000077\n18                    every man     3            3      2  6.81474553\n19                    those who     3            3      2  5.33475080\n20                    any other     3            3      2  5.14322180\n21                  moment when     3            3      2  8.28226379\n22               british empire     3            3      2  6.15939978\n23                        if we     5            5      2  3.78287487\n24                      in this     9            9      2  2.76327423\n25                     has been     3            3      2  4.78530883\n26                     hitler |     3            3      2  5.48503401\n27                    they have     7            7      2  3.02149840\n28                    would not     4            4      2  4.00664535\n29                      be able     4            4      2  4.71766519\n30                      who are     4            4      2  3.96672558\n31                     shall be     4            4      2  4.46431962\n32                    upon this     4            4      2  3.93596461\n33                   the french    13           13      2  3.26116438\n34                  some people     2            2      2  6.05754071\n35                 present time     3            3      2  6.94560866\n36                  this island     6            6      2  6.18424052\n37                   four years     2            2      2  6.64580002\n38                       on the    14           14      2  2.37337877\n39                   large size     3            3      2  6.75408033\n40                    world war     4            4      2  6.37708284\n41                    when they     3            3      2  4.85510627\n42                       have a     9            9      2  2.45526687\n43             injured machines     2            2      2  7.94602763\n44                   only three     2            2      2  5.87306420\n45             fighter strength     2            2      2  7.60931932\n46                    take part     2            2      2  7.60931932\n47              terrible losses     2            1      2  7.60931932\n48                     had been     3            3      2  4.24980235\n49                        up to     7            7      2  4.25840419\n50                 great battle     3            3      2  4.20993260\n51                        war |     3            3      2  4.20993260\n52                   very great     3            3      2  4.19181206\n53                    france or     3            3      2  4.22582439\n54                     is being     3            3      2  5.48361069\n55           untiring vigilance     2            2      2  8.45708927\n56                       no way     2            2      2  6.09831080\n57                   search his     2            2      2  7.15686188\n58                 other people     2            2      2  5.30914372\n59                        it is     5            5      2  3.19216660\n60                       we are     7            7      2  2.77101592\n61                    could not     3            3      2  4.37496736\n62                     we could     5            5      2  4.09442126\n63                    called up     2            2      2  5.99799082\n64                     stand up     2            2      2  5.99799082\n65                       it was     4            4      2  3.56446849\n66                       at the    15           15      2  2.00888130\n67                   large army     2            2      2  5.23490414\n68                large numbers     2            2      2  5.82316423\n69            continuous battle     2            2      2  5.74596650\n70                very powerful     2            2      2  5.33756176\n71            british divisions     2            2      2  4.95679875\n72                 france could     2            2      2  4.80698647\n73                  french army     2            2      2  5.01908219\n74                     from the    11           11      2  2.44751501\n75                         i do     3            3      2  3.92646524\n76                      at home     3            3      2  4.64046583\n77                       i have     6            6      2  2.70486215\n78                      if they     3            3      2  3.75435368\n79               great question     2            2      2  5.09299192\n80                 british navy     2            2      2  4.52076978\n81                       far as     2            2      2  4.69633957\n82                     which we     5            5      2  2.87124302\n83                 bomber force     2            2      2  6.25702881\n84                    are going     3            3      2  5.80776917\n85                       by the    10           10      2  2.51394657\n86                    all these     3            3      2  3.68488845\n87                       may be     3            3      2  3.87737192\n88                      must be     3            3      2  3.87737192\n89                      upon us     2            1      2  4.44907373\n90                 if necessary     2            2      2  6.18533316\n91                    very soon     2            2      2  6.18533316\n92                fighting with     2            2      2  4.52904835\n93                   clear that     3            3      2  4.85957385\n94                   modern air     2            2      2  4.94199832\n95                     three or     2            2      2  4.94199832\n96                     they had     3            3      2  3.60667270\n97                      what we     3            3      2  4.02690551\n98            french government     2            2      2  6.11840505\n99                      the war    11           11      2  2.29002789\n100                  german air     2            2      2  4.69044664\n101                    we shall     4            4      2  3.68107395\n102                  or whether     2            2      2  4.85257628\n103                 the british     9            9      2  3.06431686\n104                     able to     7            7      2  5.10618884\n105                     or four     2            2      2  5.18928582\n106                   history |     2            2      2  4.32990322\n107                      as far     2            2      2  4.44383891\n108                     that we     6            6      2  2.48315297\n109                   the enemy     9            9      2  3.51681303\n110                 troops were     2            2      2  4.27702218\n111                 our fighter     3            3      2  4.67693597\n112               received from     2            2      2  5.88788307\n113                     we were     5            5      2  2.79224148\n114                  during the     8            8      2  3.48739375\n115               final victory     2            2      2  9.55593752\n116      long-distance blockade     2            2      2  9.55593752\n117                  all europe     2            2      2  4.59018731\n118                     or lose     2            2      2  5.70034869\n119                 down safely     2            2      2  9.04487593\n120                      not be     4            4      2  2.88690265\n121                    fight on     2            2      2  4.37220930\n122                    it would     3            3      2  3.36535269\n123                   battle in     4            4      2  3.17576094\n124                is concerned     2            2      2  5.61819611\n125                     he will     2            2      2  4.30613645\n126                 even though     2            2      2  8.70816768\n127             general weygand     2            2      2  8.70816768\n128                    or other     2            2      2  3.96408572\n129                     are now     2            2      2  4.13772662\n130                 question is     2            2      2  5.54221378\n131                   that time     3            3      2  3.35901837\n132                     were at     3            3      2  3.18946194\n133                 invasion on     2            2      2  4.00400895\n134                      of our    10           10      2  1.85440967\n135                   relied on     2            2      2  5.47153452\n136                    enemy is     2            2      2  3.93135018\n137              are absolutely     2            2      2  5.43796051\n138                       i put     2            2      2  5.40546200\n139             resistance will     2            2      2  5.40546200\n140                    i should     2            2      2  3.93793587\n141                 lies before     2            2      2  8.25571036\n142                  with their     3            3      2  3.11042341\n143                    to fight     5            5      2  4.74011534\n144                    with any     2            2      2  3.71476113\n145                    get down     2            2      2 10.65478571\n146               united states     2            2      2 10.65478571\n147           winston churchill     2            1      2 10.65478571\n148                  at dunkirk     2            2      2  4.27960214\n149                   before it     2            2      2  3.95671298\n150                   north sea     2            2      2  8.08842009\n151              superiority at     2            2      2  5.28496572\n152                      put it     2            2      2  5.25694823\n153                     both in     3            3      2  3.80208748\n154                   we should     3            3      2  3.41813148\n155                    there is     2            2      2  3.59416434\n156                       as it     3            3      2  2.95384177\n157                this country     2            2      2  3.82714020\n158                  which they     3            3      2  2.93526133\n159                       but i     2            2      2  3.51799981\n160                  other hand     2            2      2  7.70822158\n161                     time in     3            3      2  3.34961955\n162                     we must     3            3      2  3.25083626\n163                     than we     2            2      2  3.87050871\n164                     a large     3            3      2  3.00984097\n165                   should be     2            2      2  3.65984762\n166                     are not     3            3      2  2.85689393\n167                       and i     5            5      2  2.51400526\n168                      to our     8            8      2  1.84443313\n169                     that he     2            2      2  4.00399149\n170                     when we     2            2      2  3.66959918\n171                   this also     2            2      2  3.51650823\n172                     that if     2            2      2  3.75243795\n173       british expeditionary     2            2      2  7.35587773\n174         expeditionary force     2            2      2  7.35587773\n175                      war II     2            2      2  7.35587773\n176                machines and     3            3      2  4.56498715\n177                very serious     2            2      2  7.28418214\n178                   a general     2            2      2  4.18570996\n179                  they would     2            2      2  3.30617956\n180                      it may     2            2      2  3.39110648\n181                    the last     7            7      2  4.12191377\n182                     a scale     2            2      2  3.84899815\n183                    in order     3            3      2  4.50554869\n184                    will not     3            3      2  2.69912841\n185                    raids by     2            2      2  7.15449698\n186                these shores     2            1      2  7.15449698\n187                     at that     4            4      2  2.36423490\n188                       to be     7            7      2  1.86518530\n189                     for the     8            8      2  1.93349013\n190                   of course     4            1      2  4.27654320\n191                      a good     2            2      2  4.69677511\n192                        i am     3            3      2  6.87304503\n193                   troops we     2            2      2  3.35896641\n194                      to one     3            3      2  3.42525035\n195                  | american     2            2      2  7.03961297\n196                       as we     3            3      2  2.65977153\n197                    have not     4            4      2  2.33761994\n198                  have fully     2            2      2  4.63472899\n199                  have given     2            2      2  4.63472899\n200               have received     2            2      2  4.63472899\n201                    who have     3            3      2  2.68420923\n202                   this time     2            2      2  3.17932000\n203                     come to     3            3      2  4.31242560\n204                     a great     3            3      2  2.64762657\n205                     our own     4            4      2  6.55668542\n206                 to continue     3            3      2  4.27303559\n207                     to give     3            3      2  4.27303559\n208                    to stand     3            3      2  4.27303559\n209                  house that     2            2      2  3.16468912\n210                   which was     2            2      2  3.06675415\n211                   is crafty     2            2      2  6.71704570\n212                      we did     2            2      2  3.85934529\n213                  these will     2            2      2  3.00399530\n214                   navy have     2            2      2  3.30480748\n215                   forces to     3            3      2  2.84487110\n216                      out of     3            3      2  3.52676431\n217                     it will     3            3      2  2.46904585\n218                    carry on     2            2      2  6.57038433\n219                     part in     2            2      2  3.79157600\n220                   we cannot     2            2      2  4.37041182\n221                   all kinds     2            2      2  6.53681038\n222                   of hitler     3            3      2  3.17155672\n223                 this battle     2            2      2  2.92728907\n224                 superior in     2            2      2  4.30264288\n225              our submarines     3            3      2  6.28685195\n226                     army in     2            2      2  3.45486245\n227                     be very     2            2      2  2.90546175\n228                     loss of     3            3      2  4.03783563\n229                    power of     3            3      2  4.03783563\n230                    with all     2            2      2  2.85205092\n231                        be a     4            4      2  2.10566493\n232                   have also     2            2      2  3.02385171\n233                   will have     4            4      2  2.10825138\n234                      only a     2            2      2  2.97660942\n235                    duty and     2            2      2  4.21861384\n236                    free and     2            2      2  4.21861384\n237                  in numbers     2            2      2  3.64866290\n238                      a navy     2            2      2  2.96049620\n239                  could have     2            2      2  2.99417230\n240                      we had     3            3      2  2.44655859\n241                 be restored     2            2      2  6.27609609\n242                    at least     2            2      2  6.22622708\n243                  it reaches     2            2      2  6.22622708\n244                    it seems     2            2      2  6.22622708\n245                        at a     4            4      2  2.05322204\n246                    this was     2            2      2  2.78866078\n247                     for all     2            2      2  2.75848311\n248                  from which     2            2      2  2.75848311\n249                    of these     4            4      2  2.23719973\n250                   in europe     2            2      2  3.31194853\n251                    of those     3            3      2  2.71907953\n252                 forget that     2            2      2  6.11127659\n253                   the house    11           11      2  5.66090383\n254                  across the     4            4      2  3.68562797\n255                    where we     2            2      2  6.06868806\n256                     four to     2            2      2  3.45713240\n257                       me to     2            2      2  3.45713240\n258                      a time     2            2      2  2.74870720\n259                    given to     2            2      2  3.96820139\n260                    order to     2            2      2  3.96820139\n261                  our duties     2            2      2  5.93219739\n262           our long-distance     2            2      2  5.93219739\n263                  the german     4            4      2  3.60168369\n264                     to take     2            2      2  3.41803135\n265                    going to     4            4      2  5.67040817\n266                  to prevent     4            4      2  5.63072475\n267               vigilance and     3            3      2  5.66384110\n268                   a million     2            2      2  5.79562686\n269                       to me     2            2      2  3.08131539\n270                   the great     6            6      2  1.77537503\n271               have suffered     2            2      2  5.73358097\n272                 the germans     8            8      2  5.34909908\n273                    that was     2            2      2  2.51304122\n274                 the history     4            4      2  2.30137886\n275                   and after     2            2      2  3.23494539\n276               and munitions     2            2      2  3.23494539\n277                    house of     3            3      2  2.30151340\n278                   which are     2            2      2  2.45458523\n279                        on a     3            3      2  2.07983763\n280                  devoted to     3            3      2  5.41128120\n281            possibilities of     2            2      2  3.69541099\n282                     and who     3            3      2  2.24094837\n283                    with the     6            6      2  1.65841180\n284                     line of     2            2      2  3.18433967\n285                munitions of     2            2      2  3.18433967\n286                  of britain     2            2      2  3.16595469\n287                of munitions     2            2      2  3.16595469\n288                 against the     3            3      2  2.91986710\n289                    not have     3            3      2  2.04103934\n290                      by our     2            2      2  2.40058312\n291                   and there     2            2      2  2.89822788\n292                       II in     2            2      2  5.40149636\n293                    the navy     4            4      2  2.13406915\n294                      and in    10           10      2  1.16836798\n295                  which will     2            2      2  2.35378390\n296            best-trained and     2            2      2  5.31746780\n297                 channel and     2            2      2  5.31746780\n298                  crafty and     2            2      2  5.31746780\n299                     the end     3            3      2  3.34725399\n300                    the line     3            3      2  3.34725399\n301                  the moment     3            3      2  3.34725399\n302                  defense of     2            2      2  2.84762167\n303                the question     3            3      2  2.83617301\n304                       we do     2            2      2  2.42233143\n305                    of three     2            2      2  2.82923651\n306                beginning of     3            3      2  5.13669356\n307                  capable of     3            3      2  5.13669356\n308                    in spite     2            2      2  5.25858489\n309                  of commons     3            3      2  5.11820451\n310                   all their     2            2      2  2.29459411\n311                      but we     2            2      2  2.30246521\n312                       was a     2            2      2  2.31139466\n313                 the present     5            5      2  4.90434697\n314                    might of     2            2      2  2.59606142\n315                     the air     6            6      2  1.51483885\n316                     easy to     2            2      2  5.06705699\n317                   likely to     2            2      2  5.06705699\n318                  to destroy     2            2      2  5.02795653\n319                       in no     2            2      2  2.31196568\n320                      of any     3            3      2  1.98000294\n321                    of large     3            3      2  1.98000294\n322                continue the     4            4      2  4.78449400\n323                    could to     2            2      2  2.35730238\n324                      at all     2            2      2  2.14175844\n325                  the allies     4            3      2  4.70055128\n326               the beginning     4            4      2  4.70055128\n327                   the whole     4            4      2  4.70055128\n328                 the country     3            3      2  2.24787542\n329            and consequently     2            1      2  4.84487368\n330                     in many     2            2      2  2.21163968\n331                   defeat of     2            2      2  4.79426892\n332                   masses of     2            2      2  4.79426892\n333                    sense of     2            2      2  4.79426892\n334                    spite of     2            2      2  4.79426892\n335                     task of     2            2      2  4.79426892\n336                  of opinion     2            2      2  4.77588431\n337                     at this     2            2      2  2.07568137\n338                   this will     2            2      2  2.07568137\n339                      war in     2            2      2  2.10251939\n340                  beyond the     3            3      2  4.52981256\n341                     the sea     3            3      2  2.04694917\n342                 invasion of     2            2      2  2.22784482\n343                    house to     2            2      2  2.12042609\n344                    of every     2            2      2  2.20945912\n345                        as a     2            2      2  1.99979690\n346               the admiralty     3            3      2  4.44612158\n347                   the coast     3            3      2  4.44612158\n348                    the most     3            3      2  4.44612158\n349                    the past     3            3      2  4.44612158\n350               the skagerrak     3            3      2  4.44612158\n351                   the worst     3            3      2  4.44612158\n352                   the first     2            2      2  3.00767616\n353                   the local     2            2      2  3.00767616\n354                      to the    18           18      2  0.74810073\n355                 british and     2            2      2  2.01848475\n356                     all our     2            2      2  1.95063112\n357                      on our     2            2      2  1.95063112\n358                   about the     2            2      2  2.58003916\n359                 between the     2            2      2  2.58003916\n360                 through the     2            2      2  2.58003916\n361                     that is     2            2      2  1.93681374\n362               will have the     2            0      3  4.21043524\n363                 of fighting     2            2      2  2.06611209\n364                 of invasion     2            2      2  2.06611209\n365                  the battle     4            4      2  1.56224520\n366                       to do     2            2      2  1.98099536\n367               the dominions     2            2      2  2.49659518\n368                  the future     2            2      2  2.49659518\n369                    the loss     2            2      2  2.49659518\n370                        is a     2            2      2  1.87391156\n371                    that the     9            9      2  0.98284266\n372                    read the     2            2      2  4.18998462\n373                   since the     2            2      2  4.18998462\n374                 because the     2            2      2  2.24331305\n375                 prevent the     2            2      2  2.24331305\n376                 whether the     2            2      2  2.24331305\n377                   that this     2            2      2  1.80004985\n378                   the other     3            3      2  1.73628293\n379                the capacity     2            2      2  4.10654375\n380                 the channel     2            2      2  4.10654375\n381              the disastrous     2            2      2  4.10654375\n382                  the ground     2            2      2  4.10654375\n383              the individual     2            2      2  4.10654375\n384                  the masses     2            2      2  4.10654375\n385                   the north     2            2      2  4.10654375\n386                  the oceans     2            2      2  4.10654375\n387                 the subject     2            2      2  4.10654375\n388                    the task     2            2      2  4.10654375\n389                  the united     2            2      2  4.10654375\n390                  the winter     2            2      2  4.10654375\n391                       is to     3            3      2  1.51360508\n392           the possibilities     2            2      2  2.15986751\n393                  that their     2            2      2  1.70835570\n394                     of this     4            4      2  1.29071041\n395                    then the     2            2      2  1.99174469\n396                   and their     4            4      2  1.26293740\n397                   battle of     2            2      2  1.74728737\n398                      but in     2            2      2  1.63521886\n399                 the defense     2            2      2  1.90829759\n400                   the power     2            2      2  1.90829759\n401                    to be of     2            0      3  4.12513311\n402               the troops we     2            0      3  6.04501317\n403                    of their     4            4      2  1.19311764\n404                    into the     2            2      2  1.79081999\n405                     and any     2            2      2  1.62305198\n406                  which have     2            2      2  1.55330672\n407                      any of     2            2      2  1.57244143\n408                   the world     2            2      2  1.70737134\n409                        in a     4            4      2  1.05473542\n410                   to france     2            2      2  1.41264462\n411                     all the     5            5      2  0.97433614\n412                    that our     2            2      2  1.36437325\n413                    upon the     3            3      2  1.23067201\n414                     and all     3            3      2  1.13765742\n415                      and on     3            3      2  1.13765742\n416                  the war in     2            0      3  3.42223897\n417                      are in     2            2      2  1.28336118\n418                the fighting     2            2      2  1.39670510\n419                the invasion     2            2      2  1.39670510\n420                      of all     3            3      2  1.06824731\n421               the navy have     2            0      3  3.63700424\n422                    in which     2            2      2  1.17400517\n423                  the troops     2            2      2  1.15980474\n424                 that of the     2            0      3  2.59536950\n425                    in their     2            2      2  1.01621689\n426            and munitions of     2            0      3  3.35281385\n427                       it in     2            2      2  0.97271869\n428                       in it     2            2      2  0.95937585\n429                     but the     3            3      2  0.81115337\n430           the history place     4            0      3  3.62379894\n431                     to this     2            2      2  0.87724231\n432                 and in many     2            0      3  2.41133627\n433               invasion on a     2            0      3  2.86311014\n434                  we were at     2            0      3  2.26070989\n435                      if the     2            2      2  0.81913052\n436                would not be     3            0      3  2.29300634\n437            munitions of all     2            0      3  2.70591444\n438            the great battle     2            0      3  2.08451072\n439               of large size     3            0      3  2.95810047\n440                      and we     3            3      2  0.62213115\n441                       to it     2            2      2  0.72868969\n442                the last war     4            0      3  2.52329119\n443             in the fighting     2            0      3  2.30886135\n444                 of hitler |     2            0      3  2.46280225\n445                      in our     2            2      2  0.67219069\n446                      all of     2            2      2  0.67599949\n447                 have a navy     2            0      3  2.18455398\n448                that we have     4            0      3  1.65423970\n449                 in spite of     2            0      3  2.62141212\n450                  or four to     2            0      3  2.30941542\n451               the battle in     2            0      3  1.21498932\n452             the invasion of     2            0      3  1.99108738\n453          the great question     2            0      3  2.06821001\n454                  and in the     5            0      3  0.66471346\n455               of the troops     2            0      3  1.64421051\n456                     have to     3            3      2  0.50474533\n457              in the defense     2            0      3  1.94055118\n458          machines and their     2            0      3  2.15065888\n459          have received from     2            0      3  2.28587655\n460               not have been     2            0      3  1.85133066\n461                 of three or     2            0      3  1.93785902\n462                    up to it     2            0      3  1.86520477\n463                in france or     3            0      3  1.44252766\n464                it would not     2            0      3  1.24667570\n465             great battle in     2            0      3  1.22223784\n466                       be of     2            2      2  0.41519612\n467              the defense of     2            0      3  1.37116763\n468               is crafty and     2            0      3  1.73400678\n469                a large army     2            0      3  1.38969109\n470            house of commons     3            0      3  1.69760164\n471              devoted to the     3            0      3  1.38655127\n472               the north sea     2            0      3  1.60084802\n473                 in order to     2            0      3  1.27578742\n474                  would be a     2            0      3  0.89460308\n475               would be very     2            0      3  1.10102970\n476                on the other     2            0      3  0.85468267\n477                  in the air     3            0      3  0.54011208\n478                    and that     2            2      2  0.30093424\n479                of all kinds     2            0      3  1.22432922\n480            the present time     3            0      3  1.21154854\n481          from the dominions     2            0      3  1.00624199\n482                from the air     2            0      3  0.74529849\n483                     and our     2            2      2  0.25832679\n484               the battle of     2            0      3  0.64099965\n485                at this time     2            0      3  0.81714934\n486              to the subject     2            0      3  0.92970175\n487                   in no way     2            0      3  0.87109708\n488                   war II in     2            0      3  1.02867925\n489             to continue the     3            0      3  0.77696509\n490                at that time     3            0      3  0.62457095\n491                  and on the     2            0      3  0.38099584\n492              channel and in     2            0      3  0.84861882\n493                 but we have     2            0      3  0.57910851\n494                   up to the     2            0      3  0.48763357\n495              the other hand     2            0      3  0.64187640\n496        the possibilities of     2            0      3  0.52328317\n497             the channel and     2            0      3  0.58044228\n498                the enemy is     2            0      3  0.37150488\n499                i have given     2            0      3  0.44089259\n500             i have received     2            0      3  0.44089259\n501                take part in     2            0      3  0.51541526\n502             the moment when     3            0      3  0.46233870\n503                   we have a     5            0      3  0.19848111\n504                 four to one     2            0      3  0.38383307\n505                are going to     3            0      3  0.37596093\n506                     that of     2            2      2  0.08956938\n507            beginning of the     3            0      3  0.30566837\n508             with the french     4            0      3  0.12099904\n509            the british navy     2            0      3  0.16314448\n510                 to fight on     2            0      3  0.15772099\n511                   which the     2            2      2  0.03895378\n512                  we are now     2            0      3  0.05091046\n513                       and a     2            2      2  0.00124533\n514                power of our     2            0      3 -0.02900181\n515               three or four     2            0      3 -0.04576585\n516                  it will be     2            0      3 -0.04570850\n517              across the sea     2            0      3 -0.07089465\n518        of our long-distance     2            0      3 -0.09314070\n519                 part in the     2            0      3 -0.08697031\n520                a very large     3            0      3 -0.09389475\n521                   at a time     2            0      3 -0.10109901\n522            the beginning of     3            0      3 -0.22129243\n523              in the channel     2            0      3 -0.25784316\n524                in the north     2            0      3 -0.25784316\n525                        of a     2            2      2 -0.06778577\n526                 have a very     2            0      3 -0.18231409\n527                a very great     2            0      3 -0.20660641\n528                of the enemy     3            0      3 -0.19362894\n529                 in the line     2            0      3 -0.26131025\n530                  at the end     2            0      3 -0.42744401\n531               the masses of     2            0      3 -0.57562228\n532                 the task of     2            0      3 -0.57562228\n533               on the ground     2            0      3 -0.60987747\n534                    i do not     3            0      3 -0.43350618\n535                 as we could     2            0      3 -0.40584719\n536                   as far as     2            0      3 -0.55572506\n537              of the british     2            0      3 -0.41950537\n538                  be able to     4            0      3 -0.47876737\n539             enemy is crafty     2            0      3 -0.81631205\n540                      be the     2            2      2 -0.18940722\n541           the united states     2            0      3 -0.96581049\n542 british expeditionary force     2            0      3 -0.87720057\n543                 the loss of     2            0      3 -0.58513312\n544                the power of     2            0      3 -0.58513312\n545            defeat of hitler     2            0      3 -0.96292060\n546              in the british     2            0      3 -0.59315322\n547        injured machines and     2            0      3 -0.94417070\n548               we have fully     2            0      3 -0.85885709\n549                the house to     2            0      3 -0.83379346\n550          the british empire     3            0      3 -0.82504604\n551                we are going     2            0      3 -0.82759641\n552             the french army     2            0      3 -0.87029481\n553              in this island     4            0      3 -1.07249341\n554                 stand up to     2            0      3 -1.14664008\n555            continue the war     3            0      3 -1.10916256\n556   the british expeditionary     2            0      3 -1.30105803\n557                   we do not     2            0      3 -0.91959736\n558              the house that     2            0      3 -1.18106832\n559  our long-distance blockade     2            0      3 -1.69960669\n560                to the house     3            0      3 -1.25779983\n561            in the skagerrak     2            0      3 -1.36021486\n562                we have also     2            0      3 -1.12657366\n563                     and the     9            9      2 -0.21772333\n564            battle in france     4            0      3 -1.24443607\n565                    have the     3            3      2 -0.37742324\n566                will be able     2            0      3 -1.30468767\n567      untiring vigilance and     2            0      3 -2.04305451\n568              at the present     3            0      3 -1.62727107\n569                  to our own     2            0      3 -1.66040436\n570                 of the last     2            0      3 -1.40180166\n571         since the beginning     2            0      3 -2.46712398\n572           shall be restored     2            0      3 -2.20366842\n573                 in the last     2            0      3 -1.57577380\n574             present time in     2            0      3 -2.20428886\n575            at the beginning     2            0      3 -2.04070435\n576              a very serious     2            0      3 -2.42086241\n577                  of the war     3            0      3 -0.99431215\n578       the french government     2            0      3 -2.48030309\n579                      and of     3            3      2 -0.66833247\n580               for the house     2            0      3 -2.73031869\n581               at the moment     2            0      3 -2.67258549\n582               able to stand     2            0      3 -3.07594937\n583             during the last     2            0      3 -2.80578963\n584                the house of     3            0      3 -3.09306477\n585              lies before us     2            0      3 -4.07374421\n586               which we have     2            0      3 -1.77408459\n587                world war II     2            0      3 -4.69294214\n588             get down safely     2            0      3 -6.22244398\n589             able to prevent     2            0      3 -4.69379138\n590                 we have not     2            0      3 -2.28835487\n               z\n1   13.838377952\n2    9.802112064\n3    9.490914301\n4    8.975845372\n5    8.798029151\n6    8.517547894\n7    8.517366125\n8    8.491078766\n9    8.387251589\n10   8.065337518\n11   8.063589302\n12   8.052359534\n13   7.886519981\n14   7.595002748\n15   7.542494537\n16   7.530490015\n17   7.496615768\n18   7.436396382\n19   7.365829867\n20   7.228639414\n21   7.121338501\n22   7.037815859\n23   7.012639313\n24   6.990074915\n25   6.961128375\n26   6.917037500\n27   6.902221744\n28   6.883253976\n29   6.871564613\n30   6.860934041\n31   6.811229396\n32   6.786561270\n33   6.779598947\n34   6.754505748\n35   6.752925888\n36   6.717962893\n37   6.706246075\n38   6.666035700\n39   6.624277253\n40   6.592774083\n41   6.562214308\n42   6.560735771\n43   6.560688457\n44   6.551569752\n45   6.542720685\n46   6.542720685\n47   6.542720685\n48   6.527484127\n49   6.514313300\n50   6.472265881\n51   6.472265881\n52   6.463245600\n53   6.444542979\n54   6.432335908\n55   6.423183190\n56   6.408633142\n57   6.404569135\n58   6.403915953\n59   6.399092662\n60   6.386628389\n61   6.348631721\n62   6.347247512\n63   6.338392821\n64   6.338392821\n65   6.282997617\n66   6.248471913\n67   6.245946285\n68   6.206679403\n69   6.145117215\n70   6.143182499\n71   6.119368743\n72   6.102287291\n73   6.055552168\n74   6.030129696\n75   6.030003613\n76   6.009079532\n77   5.963602186\n78   5.941786051\n79   5.920461289\n80   5.875798260\n81   5.874105443\n82   5.871624498\n83   5.857733832\n84   5.847323049\n85   5.830776828\n86   5.827406922\n87   5.819115173\n88   5.819115173\n89   5.807726631\n90   5.803620328\n91   5.803620328\n92   5.793032773\n93   5.775675125\n94   5.774437802\n95   5.774437802\n96   5.765831915\n97   5.759638093\n98   5.752099396\n99   5.736410133\n100  5.734697483\n101  5.707417782\n102  5.685336298\n103  5.685330830\n104  5.679592456\n105  5.652593883\n106  5.648435599\n107  5.614327775\n108  5.603705476\n109  5.599889585\n110  5.592657798\n111  5.572909145\n112  5.568038217\n113  5.534887704\n114  5.466201199\n115  5.456614963\n116  5.456614963\n117  5.414331380\n118  5.411855220\n119  5.405119470\n120  5.402792508\n121  5.396727230\n122  5.384429867\n123  5.360059083\n124  5.341900983\n125  5.323907416\n126  5.313464635\n127  5.313464635\n128  5.295162615\n129  5.276910267\n130  5.276461969\n131  5.246491025\n132  5.228756422\n133  5.221711983\n134  5.218125365\n135  5.215001452\n136  5.207498571\n137  5.185619910\n138  5.157070470\n139  5.157070470\n140  5.144969259\n141  5.137735699\n142  5.133760833\n143  5.122330045\n144  5.107349789\n145  5.079333640\n146  5.079333640\n147  5.079333640\n148  5.078777992\n149  5.068322202\n150  5.061115517\n151  5.050338925\n152  5.025336263\n153  4.981743073\n154  4.937072724\n155  4.928418283\n156  4.918740167\n157  4.915675785\n158  4.906050514\n159  4.898813834\n160  4.869754046\n161  4.841902735\n162  4.838741867\n163  4.826537537\n164  4.826346590\n165  4.813168581\n166  4.795313169\n167  4.790800713\n168  4.774981731\n169  4.771046893\n170  4.726904471\n171  4.708945456\n172  4.687582030\n173  4.676354082\n174  4.676354082\n175  4.676354082\n176  4.652889577\n177  4.635562823\n178  4.633694074\n179  4.632303193\n180  4.606265463\n181  4.598663737\n182  4.594850319\n183  4.593643548\n184  4.562184099\n185  4.560759444\n186  4.560759444\n187  4.547856316\n188  4.541157764\n189  4.533084102\n190  4.520359642\n191  4.513930678\n192  4.513602156\n193  4.512071564\n194  4.500822942\n195  4.493510504\n196  4.473406542\n197  4.465025387\n198  4.456220507\n199  4.456220507\n200  4.456220507\n201  4.415684331\n202  4.410733914\n203  4.400419643\n204  4.397100238\n205  4.379742879\n206  4.360886991\n207  4.360886991\n208  4.360886991\n209  4.359359164\n210  4.352302389\n211  4.300629987\n212  4.283749053\n213  4.280122339\n214  4.279177795\n215  4.252303571\n216  4.239799355\n217  4.213165384\n218  4.211321251\n219  4.210429006\n220  4.208674002\n221  4.190758662\n222  4.173318988\n223  4.146412524\n224  4.144822041\n225  4.141556070\n226  4.139264571\n227  4.131643729\n228  4.124113936\n229  4.124113936\n230  4.104127419\n231  4.085326082\n232  4.083348364\n233  4.079073096\n234  4.073776706\n235  4.065464758\n236  4.065464758\n237  4.055210443\n238  4.052680447\n239  4.044842037\n240  4.041375634\n241  4.029805296\n242  3.998790755\n243  3.998790755\n244  3.998790755\n245  3.993739627\n246  3.988477904\n247  3.987423619\n248  3.987423619\n249  3.984057717\n250  3.972010067\n251  3.950900064\n252  3.927062721\n253  3.915352922\n254  3.901248808\n255  3.900409758\n256  3.846091648\n257  3.846091648\n258  3.844341465\n259  3.827928505\n260  3.827928505\n261  3.814734941\n262  3.814734941\n263  3.812929716\n264  3.803266368\n265  3.796923421\n266  3.770601220\n267  3.737954353\n268  3.728662527\n269  3.700380906\n270  3.691366903\n271  3.689457262\n272  3.672856600\n273  3.615588995\n274  3.605529189\n275  3.602228764\n276  3.602228764\n277  3.596213086\n278  3.591581749\n279  3.587453308\n280  3.572959063\n281  3.567745278\n282  3.554407925\n283  3.551092734\n284  3.546526887\n285  3.546526887\n286  3.526277452\n287  3.526277452\n288  3.516816127\n289  3.516328127\n290  3.493664730\n291  3.483532207\n292  3.478733944\n293  3.464452041\n294  3.464333908\n295  3.456474179\n296  3.425215425\n297  3.425215425\n298  3.425215425\n299  3.423869981\n300  3.423869981\n301  3.423869981\n302  3.423436353\n303  3.416629332\n304  3.402271468\n305  3.401588304\n306  3.392993118\n307  3.392993118\n308  3.387672596\n309  3.380857703\n310  3.375820154\n311  3.367927062\n312  3.347224720\n313  3.317685850\n314  3.274883922\n315  3.271667273\n316  3.265357061\n317  3.265357061\n318  3.240352559\n319  3.222246358\n320  3.217147384\n321  3.217147384\n322  3.206920564\n323  3.204030692\n324  3.163927936\n325  3.150833622\n326  3.150833622\n327  3.150833622\n328  3.143643577\n329  3.123141935\n330  3.112877402\n331  3.090710341\n332  3.090710341\n333  3.090710341\n334  3.090710341\n335  3.090710341\n336  3.078924677\n337  3.073541249\n338  3.073541249\n339  3.019007088\n340  2.993822823\n341  2.982932419\n342  2.977011516\n343  2.959835361\n344  2.952716384\n345  2.946346456\n346  2.938670219\n347  2.938670219\n348  2.938670219\n349  2.938670219\n350  2.938670219\n351  2.938670219\n352  2.907599356\n353  2.907599356\n354  2.905508800\n355  2.900862369\n356  2.896121176\n357  2.896121176\n358  2.878095983\n359  2.878095983\n360  2.878095983\n361  2.871472876\n362  2.848419489\n363  2.813158486\n364  2.813158486\n365  2.794383930\n366  2.793413390\n367  2.785441620\n368  2.785441620\n369  2.785441620\n370  2.776678751\n371  2.725882654\n372  2.702595121\n373  2.702595121\n374  2.701966667\n375  2.701966667\n376  2.701966667\n377  2.682356566\n378  2.671477162\n379  2.648911187\n380  2.648911187\n381  2.648911187\n382  2.648911187\n383  2.648911187\n384  2.648911187\n385  2.648911187\n386  2.648911187\n387  2.648911187\n388  2.648911187\n389  2.648911187\n390  2.648911187\n391  2.616840445\n392  2.601928012\n393  2.553556003\n394  2.520323771\n395  2.517716180\n396  2.478981349\n397  2.467538468\n398  2.417711341\n399  2.412710349\n400  2.412710349\n401  2.371152412\n402  2.359325827\n403  2.343780643\n404  2.340546659\n405  2.327027685\n406  2.324913270\n407  2.255150148\n408  2.231954168\n409  2.115932734\n410  2.078917031\n411  2.068745733\n412  2.058721710\n413  2.041490296\n414  1.988503141\n415  1.988503141\n416  1.935590602\n417  1.926601749\n418  1.906527329\n419  1.906527329\n420  1.868334565\n421  1.823108317\n422  1.762992473\n423  1.626253543\n424  1.567235081\n425  1.534566990\n426  1.500078436\n427  1.474772685\n428  1.451362989\n429  1.394996918\n430  1.388837336\n431  1.323355397\n432  1.323161699\n433  1.246351845\n434  1.214349765\n435  1.191571026\n436  1.181568409\n437  1.151268547\n438  1.120651718\n439  1.114359062\n440  1.111507744\n441  1.104737503\n442  1.103863737\n443  1.075853127\n444  1.047199251\n445  1.024883726\n446  1.020303610\n447  1.007439668\n448  0.990973383\n449  0.984901180\n450  0.981881115\n451  0.962564153\n452  0.929732460\n453  0.926220761\n454  0.924974910\n455  0.916025328\n456  0.908336701\n457  0.897594396\n458  0.894912055\n459  0.855692033\n460  0.852718172\n461  0.844594470\n462  0.841777489\n463  0.663438336\n464  0.654480304\n465  0.637377132\n466  0.632067281\n467  0.631252037\n468  0.596264351\n469  0.594862276\n470  0.585390980\n471  0.549468065\n472  0.547226692\n473  0.531923996\n474  0.502857903\n475  0.501506723\n476  0.465926436\n477  0.464538505\n478  0.460000099\n479  0.459059919\n480  0.455917553\n481  0.450500126\n482  0.440055964\n483  0.395281157\n484  0.373193713\n485  0.371704571\n486  0.365379134\n487  0.360164193\n488  0.352992073\n489  0.344600452\n490  0.337961158\n491  0.333762049\n492  0.329189153\n493  0.321461178\n494  0.284126504\n495  0.239146167\n496  0.231733150\n497  0.228066854\n498  0.205918067\n499  0.190765667\n500  0.190765667\n501  0.188466347\n502  0.184349949\n503  0.182718094\n504  0.158361169\n505  0.157975365\n506  0.137468823\n507  0.121562450\n508  0.093566456\n509  0.086712719\n510  0.078218344\n511  0.059037691\n512  0.026869783\n513  0.001915939\n514 -0.014715331\n515 -0.017133726\n516 -0.032541840\n517 -0.034113805\n518 -0.036393392\n519 -0.044663727\n520 -0.051050551\n521 -0.056368285\n522 -0.088035783\n523 -0.101511557\n524 -0.101511557\n525 -0.104337612\n526 -0.107617198\n527 -0.111420070\n528 -0.115895760\n529 -0.134312237\n530 -0.217627128\n531 -0.226959568\n532 -0.226959568\n533 -0.238400835\n534 -0.239672280\n535 -0.244456549\n536 -0.249436791\n537 -0.252848856\n538 -0.259585296\n539 -0.278468132\n540 -0.289205782\n541 -0.299427213\n542 -0.299816321\n543 -0.301522649\n544 -0.301522649\n545 -0.352243835\n546 -0.356581553\n547 -0.372903400\n548 -0.378527751\n549 -0.384618605\n550 -0.414661419\n551 -0.415222420\n552 -0.450624908\n553 -0.471712897\n554 -0.487041866\n555 -0.489099336\n556 -0.501921096\n557 -0.523305428\n558 -0.531669489\n559 -0.563757681\n560 -0.591753342\n561 -0.601225471\n562 -0.607929855\n563 -0.640716720\n564 -0.671322997\n565 -0.684111386\n566 -0.726512922\n567 -0.734167490\n568 -0.741505208\n569 -0.743458260\n570 -0.773312748\n571 -0.831493901\n572 -0.832388145\n573 -0.867389280\n574 -0.902299253\n575 -0.919608119\n576 -0.935850077\n577 -1.035715290\n578 -1.074344111\n579 -1.223859992\n580 -1.252031631\n581 -1.360309487\n582 -1.435700598\n583 -1.460275049\n584 -1.468508538\n585 -1.484115044\n586 -1.581601032\n587 -1.707496844\n588 -1.870455540\n589 -1.973484345\n590 -2.171624798"
  },
  {
    "objectID": "posts/LabPCA.html",
    "href": "posts/LabPCA.html",
    "title": "Principle Component Analysis",
    "section": "",
    "text": "## Gentle Machine Learning\n## Principal Component Analysis\n\n\n# Dataset: USArrests is the sample dataset used in \n# McNeil, D. R. (1977) Interactive Data Analysis. New York: Wiley.\n# Murder    numeric Murder arrests (per 100,000)\n# Assault   numeric Assault arrests (per 100,000)\n# UrbanPop  numeric Percent urban population\n# Rape  numeric Rape arrests (per 100,000)\n# For each of the fifty states in the United States, the dataset contains the number \n# of arrests per 100,000 residents for each of three crimes: Assault, Murder, and Rape. \n# UrbanPop is the percent of the population in each state living in urban areas.\nlibrary(datasets)\nlibrary(ISLR)\narrest = USArrests\nstates=row.names(USArrests)\nnames(USArrests)\n\n[1] \"Murder\"   \"Assault\"  \"UrbanPop\" \"Rape\"    \n\n\n\n# Get means and variances of variables\napply(USArrests, 2, mean)\n\n  Murder  Assault UrbanPop     Rape \n   7.788  170.760   65.540   21.232 \n\n\n\napply(USArrests, 2, var)\n\n    Murder    Assault   UrbanPop       Rape \n  18.97047 6945.16571  209.51878   87.72916 \n\n\n\n# PCA with scaling\npr.out=prcomp(USArrests, scale=TRUE)\nnames(pr.out) # Five\n\n[1] \"sdev\"     \"rotation\" \"center\"   \"scale\"    \"x\"       \n\npr.out$center # the centering and scaling used (means)\n\n  Murder  Assault UrbanPop     Rape \n   7.788  170.760   65.540   21.232 \n\npr.out$scale # the matrix of variable loadings (eigenvectors)\n\n   Murder   Assault  UrbanPop      Rape \n 4.355510 83.337661 14.474763  9.366385 \n\npr.out$rotation\n\n                PC1        PC2        PC3         PC4\nMurder   -0.5358995  0.4181809 -0.3412327  0.64922780\nAssault  -0.5831836  0.1879856 -0.2681484 -0.74340748\nUrbanPop -0.2781909 -0.8728062 -0.3780158  0.13387773\nRape     -0.5434321 -0.1673186  0.8177779  0.08902432\n\ndim(pr.out$x)\n\n[1] 50  4\n\n\n\n\n\npr.out$rotation=-pr.out$rotation\npr.out$x=-pr.out$x\nbiplot(pr.out, scale=0)\n\n\n\n\n\npr.out$sdev\n\n[1] 1.5748783 0.9948694 0.5971291 0.4164494\n\npr.var=pr.out$sdev^2\npr.var\n\n[1] 2.4802416 0.9897652 0.3565632 0.1734301\n\npve=pr.var/sum(pr.var)\npve\n\n[1] 0.62006039 0.24744129 0.08914080 0.04335752\n\nplot(pve, xlab=\"Principal Component\", ylab=\"Proportion of Variance Explained\", ylim=c(0,1),type='b')\n\n\n\n\n\nplot(cumsum(pve), xlab=\"Principal Component\", ylab=\"Cumulative Proportion of Variance Explained\", ylim=c(0,1),type='b')\n\n\n\n\n\n## Use factoextra package\nlibrary(factoextra)\n\nLoading required package: ggplot2\n\n\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n\nfviz(pr.out, \"ind\", geom = \"auto\", mean.point = TRUE, font.family = \"Georgia\")\n\n\n\nfviz_pca_biplot(pr.out, font.family = \"Georgia\", col.var=\"firebrick1\")"
  },
  {
    "objectID": "posts/Assignment1.html",
    "href": "posts/Assignment1.html",
    "title": "Combining tools for better data science - Assignment 1",
    "section": "",
    "text": "In his incisive 2001 article on the “two cultures” of statistical modeling, Breiman noted the almost exclusive use of traditional statistical techniques (ie, linear regression models) in research at the time and then details all the issues he sees with using linear models (and especially, using them exclusively). He asserts that the assumptions we must make when using linear models are not tenable and the methods we have for testing the validity of linear models are insufficient. Breiman sees algorithmic predictive models as the superior approach, and admonishes fellows in his field to move towards predictive modeling.\nIn Schmueli’s 2010 article on the difference between explanatory models and predictive models, it seems not a lot has changed in terms of statisticians’ preferences for modeling. Schmueli also comments on how regression models are used almost exclusively, to the detriment of the research. However, he advocates for combining the two - gettings the best of both worlds. He stresses that explanatory and predictive models have different uses, different strengths, and should be used in different circumstances. Often, they can work together to provide a more complete picture than either one could alone. For example, with the explosion in both the volume and type of data in recent years, predictive models can help uncover new trends and associations that we might not be able to uncover simply through reviewing the theory, literature, and running regression models. The insights we gain from predictive modelling can then feed into explanatory models.\nSchmueli also advocates for more inter-disciplinary collaborations. As both he and Breiman point out, predictive modeling is more often found in the domain of computer scientists, and statisticians and social science researchers often do not venture into this domain. All parties could improve their research and find value in cross-domain collaborations.\nReferences Breiman, L. (2001). Statistical modeling: The two cultures (with comments and a rejoinder by the author). Statistical science, 16(3), 199-231.\nShmueli, G. (2010). To explain or to predict?."
  },
  {
    "objectID": "posts/Assignment4-k-means-cluster.html",
    "href": "posts/Assignment4-k-means-cluster.html",
    "title": "K-means Clustering - Assignment 4",
    "section": "",
    "text": "## Gentle Machine Learning\n## Clustering: K-means, Hierarchical Clustering\n\n## Computer purchase example: Animated illustration \n## Adapted from Guru99 tutorial (https://www.guru99.com/r-k-means-clustering.html)\n## Dataset: characteristics of computers purchased.\n## Variables used: RAM size, Harddrive size\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\nlibrary(RColorBrewer)\n\ncomputers = read.csv(\"https://raw.githubusercontent.com/guru99-edu/R-Programming/master/computers.csv\") \n\n# Only retain two variables for illustration\nrescaled_comp <- computers[4:5] %>%\n  mutate(hd_scal = scale(hd),\n         ram_scal = scale(ram)) %>%\n  select(c(hd_scal, ram_scal))\n        \nggplot(data = rescaled_comp, aes(x = hd_scal, y = ram_scal)) +\n  geom_point(pch=20, col = \"blue\") + theme_bw() +\n  labs(x = \"Hard drive size (Scaled)\", y =\"RAM size (Scaled)\" ) +\n  theme(text = element_text(family=\"Georgia\")) \n\n\n\n# install.packages(\"animation\")\nlibrary(animation)\nset.seed(2345)\nlibrary(animation)\n\n# Animate the K-mean clustering process, cluster no. = 4\nkmeans.ani(rescaled_comp[1:2], centers = 4, pch = 15:18, col = 1:4) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Iris example\n\n# Without grouping by species\nggplot(iris, aes(Petal.Length, Petal.Width)) + geom_point() + \n  theme_bw() +\n  scale_color_manual(values=c(\"firebrick1\",\"forestgreen\",\"darkblue\"))\n\n\n\n# With grouping by species\nggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point() + \n  theme_bw() +\n  scale_color_manual(values=c(\"firebrick1\",\"forestgreen\",\"darkblue\"))\n\n\n\n# Check k-means clusters\n## Starting with three clusters and 20 initial configurations\nset.seed(20)\nirisCluster <- kmeans(iris[, 3:4], 3, nstart = 20)\nirisCluster\n\nK-means clustering with 3 clusters of sizes 52, 48, 50\n\nCluster means:\n  Petal.Length Petal.Width\n1     4.269231    1.342308\n2     5.595833    2.037500\n3     1.462000    0.246000\n\nClustering vector:\n  [1] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n [38] 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [75] 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 2 2\n[112] 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2\n[149] 2 2\n\nWithin cluster sum of squares by cluster:\n[1] 13.05769 16.29167  2.02200\n (between_SS / total_SS =  94.3 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\nclass(irisCluster$cluster)\n\n[1] \"integer\"\n\n# Confusion matrix\ntable(irisCluster$cluster, iris$Species)\n\n   \n    setosa versicolor virginica\n  1      0         48         4\n  2      0          2        46\n  3     50          0         0\n\nirisCluster$cluster <- as.factor(irisCluster$cluster)\nggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster$cluster)) + geom_point() +\n  scale_color_manual(values=c(\"firebrick1\",\"forestgreen\",\"darkblue\")) +\n  theme_bw()\n\n\n\nactual = ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point() + \n  theme_bw() +\n  scale_color_manual(values=c(\"firebrick1\",\"forestgreen\",\"darkblue\")) +\n  theme(legend.position=\"bottom\") +\n  theme(text = element_text(family=\"Georgia\")) \nkmc = ggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster$cluster)) + geom_point() +\n  theme_bw() +\n  scale_color_manual(values=c(\"firebrick1\", \"darkblue\", \"forestgreen\")) +\n  theme(legend.position=\"bottom\") +\n  theme(text = element_text(family=\"Georgia\")) \nlibrary(grid)\nlibrary(gridExtra)\n\n\nAttaching package: 'gridExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\ngrid.arrange(arrangeGrob(actual, kmc, ncol=2, widths=c(1,1)), nrow=1)\n\n\n\n\n\n\n\n## Wine example\n\n# install.packages(\"rattle.data\")\n# wine dataset  contains the results of a chemical analysis of wines \n# grown in a specific area of Italy. Three types of wine are represented in the \n# 178 samples, with the results of 13 chemical analyses recorded for each sample. \n# The Type variable has been transformed into a categorical variable.\n# Variables used in this example\n# Alcohol\n# Malic: Malic acid\n# Ash\n#library(rattle.data)\n#data(wine)\n\n# the rattle package no longer works for this version of R\n# instead we will manually load the wine dataset\n\nwine <- read.table(\"wine.data\", sep = \",\", header = FALSE)\ncolnames(wine) <- c(\"class\", \"Alcohol\", \"Malic acid\", \"Ash\", \"Alcalinity of ash\", \"Magnesium\", \"Total phenols\", \"Flavanoids\", \"Nonflavanoid phenols\", \"Proanthocyanins\", \"Color intensity\", \"Hue\", \"OD280/OD315 of diluted wines\", \"Proline\")\n\n## Choose and scale variables\nwine_subset <- scale(wine[ , c(2:4)])\n\n## Create cluster using k-means, k = 3, with 25 initial configurations\nwine_cluster <- kmeans(wine_subset, centers = 3,\n                       iter.max = 10,\n                       nstart = 25)\nwine_cluster\n\nK-means clustering with 3 clusters of sizes 48, 60, 70\n\nCluster means:\n     Alcohol Malic acid        Ash\n1  0.1470536  1.3907328  0.2534220\n2  0.8914655 -0.4522073  0.5406223\n3 -0.8649501 -0.5660390 -0.6371656\n\nClustering vector:\n  [1] 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2\n [38] 2 3 1 2 1 2 1 3 1 1 2 2 2 3 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 2 3 3 2 2 2\n [75] 3 3 3 3 3 1 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n[112] 3 1 3 3 3 3 3 1 3 3 2 1 1 1 3 3 3 3 1 3 1 3 1 3 3 1 1 1 1 1 2 1 1 1 1 1 1\n[149] 1 1 1 1 2 1 3 1 1 1 2 2 1 1 1 1 2 1 1 1 2 1 3 3 2 1 1 1 2 1\n\nWithin cluster sum of squares by cluster:\n[1]  73.71460  67.98619 111.63512\n (between_SS / total_SS =  52.3 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\n# Create a function to compute and plot total within-cluster sum of square (withinss)\nwssplot <- function(data, nc=15, seed=1234){\n  wss <- (nrow(data)-1)*sum(apply(data,2,var))\n  for (i in 2:nc){\n    set.seed(seed)\n    wss[i] <- sum(kmeans(data, centers=i)$withinss)}\n  plot(1:nc, wss, type=\"b\", xlab=\"Number of Clusters\",\n       ylab=\"Within groups sum of squares\")\n}\n\n# plotting values for each cluster starting from 1 to 9\nwssplot(wine_subset, nc = 9)\n\n\n\n# Plot results by dimensions\nwine_cluster$cluster = as.factor(wine_cluster$cluster)\npairs(wine[2:4],\n      col = c(\"firebrick1\", \"darkblue\", \"forestgreen\")[wine_cluster$cluster],\n      pch = c(15:17)[wine_cluster$cluster],\n      main = \"K-Means Clusters: Wine data\")\n\n\n\ntable(wine_cluster$cluster)\n\n\n 1  2  3 \n48 60 70 \n\n## Use the factoextra package to do more\n# install.packages(\"factoextra\")\n\nlibrary(factoextra)\n\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n\nfviz_nbclust(wine_subset, kmeans, method = \"wss\")\n\n\n\n# Use eclust() procedure to do K-Means\nwine.km <- eclust(wine_subset, \"kmeans\", nboot = 2)\n\n\n\n# Print result\nwine.km\n\nK-means clustering with 3 clusters of sizes 60, 70, 48\n\nCluster means:\n     Alcohol Malic acid        Ash\n1  0.8914655 -0.4522073  0.5406223\n2 -0.8649501 -0.5660390 -0.6371656\n3  0.1470536  1.3907328  0.2534220\n\nClustering vector:\n  [1] 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 3 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1\n [38] 1 2 3 1 3 1 3 2 3 3 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 1 1 1\n [75] 2 2 2 2 2 3 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[112] 2 3 2 2 2 2 2 3 2 2 1 3 3 3 2 2 2 2 3 2 3 2 3 2 2 3 3 3 3 3 1 3 3 3 3 3 3\n[149] 3 3 3 3 1 3 2 3 3 3 1 1 3 3 3 3 1 3 3 3 1 3 2 2 1 3 3 3 1 3\n\nWithin cluster sum of squares by cluster:\n[1]  67.98619 111.63512  73.71460\n (between_SS / total_SS =  52.3 %)\n\nAvailable components:\n\n [1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n [6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"       \"clust_plot\"  \n[11] \"silinfo\"      \"nbclust\"      \"data\"         \"gap_stat\"    \n\n# Optimal number of clusters using gap statistics\nwine.km$nbclust\n\n[1] 3\n\nfviz_nbclust(wine_subset, kmeans, method = \"gap_stat\")\n\n\n\n# Silhouette plot\nfviz_silhouette(wine.km)\n\n  cluster size ave.sil.width\n1       1   60          0.44\n2       2   70          0.33\n3       3   48          0.30\n\n\n\n\nfviz_cluster(wine_cluster, data = wine_subset) + \n  theme_bw() +\n  theme(text = element_text(family=\"Georgia\")) \n\n\n\nfviz_cluster(wine_cluster, data = wine_subset, ellipse.type = \"norm\") + \n  theme_bw() +\n  theme(text = element_text(family=\"Georgia\")) \n\n\n\n## Hierarchical Clustering\n## Dataset: USArrests\n#  install.packages(\"cluster\")\narrest.hc <- USArrests %>%\n  scale() %>%                    # Scale the data\n  dist(method = \"euclidean\") %>% # Compute dissimilarity matrix\n  hclust(method = \"ward.D2\")     # Compute hierarchical clustering\n\n# Visualize using factoextra\n# Cut in 4 groups and color by groups\nfviz_dend(arrest.hc, k = 4, # Cut in four groups\n          cex = 0.5, # label size\n          k_colors = c(\"firebrick1\",\"forestgreen\",\"blue\", \"purple\"),\n          color_labels_by_k = TRUE, # color labels by groups\n          rect = TRUE, # Add rectangle around groups,\n          main = \"Cluster Dendrogram: USA Arrest data\"\n) + theme(text = element_text(family=\"Georgia\")) \n\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\nℹ The deprecated feature was likely used in the factoextra package.\n  Please report the issue at <\u001b]8;;https://github.com/kassambara/factoextra/issues\u0007https://github.com/kassambara/factoextra/issues\u001b]8;;\u0007>."
  },
  {
    "objectID": "posts/Assignment5_text-mining_word-cloud.html#example-1---martin-luther-kings-i-have-a-dream-speech",
    "href": "posts/Assignment5_text-mining_word-cloud.html#example-1---martin-luther-kings-i-have-a-dream-speech",
    "title": "Text Mining and Word Clouds - Assignment 5",
    "section": "Example 1 - Martin Luther King’s “I Have a Dream” speech",
    "text": "Example 1 - Martin Luther King’s “I Have a Dream” speech\n\n# Download text data from website\nmlk_speech <-URLencode(\"http://www.analytictech.com/mb021/mlk.htm\")\n\n# use htmlTreeParse function to read and parse paragraphs\n\ndoc.html<- htmlTreeParse(mlk_speech, useInternal=TRUE)\nmlk <- unlist(xpathApply(doc.html, '//p', xmlValue))\n\nhead(mlk, 3)\n\n[1] \"I am happy to join with you today in what will go down in\\r\\nhistory as the greatest demonstration for freedom in the history\\r\\nof our nation. \"                                                                                                                                                                                                              \n[2] \"Five score years ago a great American in whose symbolic shadow\\r\\nwe stand today signed the Emancipation Proclamation. This\\r\\nmomentous decree came as a great beckoning light of hope to\\r\\nmillions of Negro slaves who had been seared in the flames of\\r\\nwithering injustice. It came as a joyous daybreak to end the long\\r\\nnight of their captivity. \"\n[3] \"But one hundred years later the Negro is still not free. One\\r\\nhundred years later the life of the Negro is still sadly crippled\\r\\nby the manacles of segregation and the chains of discrimination. \"                                                                                                                                                        \n\n\n\nwords.vec <- VectorSource(mlk)\n\n# Check the class of words.vec\n\nclass(words.vec)\n\n[1] \"VectorSource\" \"SimpleSource\" \"Source\"      \n\n# Create Corpus object for preprocessing\nwords.corpus <- Corpus(words.vec)\ninspect(words.corpus)\n\n<<SimpleCorpus>>\nMetadata:  corpus specific: 1, document level (indexed): 0\nContent:  documents: 26\n\n [1] I am happy to join with you today in what will go down in\\r\\nhistory as the greatest demonstration for freedom in the history\\r\\nof our nation.                                                                                                                                                                                                                                                                                                                                                   \n [2] Five score years ago a great American in whose symbolic shadow\\r\\nwe stand today signed the Emancipation Proclamation. This\\r\\nmomentous decree came as a great beckoning light of hope to\\r\\nmillions of Negro slaves who had been seared in the flames of\\r\\nwithering injustice. It came as a joyous daybreak to end the long\\r\\nnight of their captivity.                                                                                                                                     \n [3] But one hundred years later the Negro is still not free. One\\r\\nhundred years later the life of the Negro is still sadly crippled\\r\\nby the manacles of segregation and the chains of discrimination.                                                                                                                                                                                                                                                                                             \n [4] One hundred years later the Negro lives on a lonely island of\\r\\npoverty in the midst of a vast ocean of material prosperity.                                                                                                                                                                                                                                                                                                                                                                     \n [5] One hundred years later the Negro is still languishing in the\\r\\ncomers of American society and finds himself in exile in his own\\r\\nland.                                                                                                                                                                                                                                                                                                                                                        \n [6] We all have come to this hallowed spot to remind America of\\r\\nthe fierce urgency of now. Now is the time to rise from the dark\\r\\nand desolate valley of segregation to the sunlit path of racial\\r\\njustice. Now is the time to change racial injustice to the solid\\r\\nrock of brotherhood. Now is the time to make justice ring out for\\r\\nall of God's children.                                                                                                                             \n [7] There will be neither rest nor tranquility in America until\\r\\nthe Negro is granted citizenship rights.                                                                                                                                                                                                                                                                                                                                                                                           \n [8] We must forever conduct our struggle on the high plane of\\r\\ndignity and discipline. We must not allow our creative protest to\\r\\ndegenerate into physical violence. Again and again we must rise\\r\\nto the majestic heights of meeting physical force with soul\\r\\nforce.                                                                                                                                                                                                                        \n [9] And the marvelous new militarism which has engulfed the Negro\\r\\ncommunity must not lead us to a distrust of all white people, for\\r\\nmany of our white brothers have evidenced by their presence here\\r\\ntoday that they have come to realize that their destiny is part\\r\\nof our destiny.                                                                                                                                                                                                      \n[10] So even though we face the difficulties of today and tomorrow\\r\\nI still have a dream. It is a dream deeply rooted in the American\\r\\ndream.                                                                                                                                                                                                                                                                                                                                                      \n[11] I have a dream that one day this nation will rise up and live\\r\\nout the true meaning of its creed: 'We hold these truths to be\\r\\nself-evident; that all men are created equal.\"                                                                                                                                                                                                                                                                                                                 \n[12] I have a dream that one day on the red hills of Georgia the\\r\\nsons of former slaves and the sons of former slave owners will be\\r\\nable to sit together at the table of brotherhood.                                                                                                                                                                                                                                                                                                             \n[13] I have a dream that one day even the state of Mississippi, a\\r\\nstate sweltering with the heat of injustice, sweltering with the\\r\\nheat of oppression, will be transformed into an oasis of freedom\\r\\nand justice.                                                                                                                                                                                                                                                                              \n[14] I have a dream that little children will one day live in a\\r\\nnation where they will not be judged by the color of their skin\\r\\nbut by the content of their character.                                                                                                                                                                                                                                                                                                                           \n[15] I have a dream today.                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n[16] I have a dream that one day down in Alabama, with its vicious\\r\\nracists, with its Governor having his lips dripping with the\\r\\nwords of interposition and nullification, one day right there in\\r\\nAlabama little black boys and black girls will be able to join\\r\\nhands with little white boys and white girls as sisters and\\r\\nbrothers.                                                                                                                                                   \n[17] I have a dream today.                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n[18] I have a dream that one day every valley shall be exalted,\\r\\nevery hill and mountain shall be made low, the rough places\\r\\nplains, and the crooked places will be made straight, and before\\r\\nthe Lord will be revealed, and all flesh shall see it together.                                                                                                                                                                                                                                  \n[19] This is our hope. This is the faith that I go back to the\\r\\nmount with. With this faith we will be able to hew out of the\\r\\nmountain of despair a stone of hope. With this faith we will be\\r\\nable to transform the genuine discords of our nation into a\\r\\nbeautiful symphony of brotherhood. With this faith we will be\\r\\nable to work together, pray together; to struggle together, to go\\r\\nto jail together, to stand up for freedom forever, )mowing that\\r\\nwe will be free one day. \n[20] And I say to you today my friends, let freedom ring. From the\\r\\nprodigious hilltops of New Hampshire, let freedom ring. From the\\r\\nmighty mountains of New York, let freedom ring. From the mighty\\r\\nAlleghenies of Pennsylvania!                                                                                                                                                                                                                                                              \n[21] Let freedom ring from the snow capped Rockies of Colorado!                                                                                                                                                                                                                                                                                                                                                                                                                                        \n[22] Let freedom ring from the curvaceous slopes of California!                                                                                                                                                                                                                                                                                                                                                                                                                                        \n[23] But not only there; let freedom ring from the Stone Mountain\\r\\nof Georgia!                                                                                                                                                                                                                                                                                                                                                                                                                       \n[24] Let freedom ring from Lookout Mountain in Tennessee!                                                                                                                                                                                                                                                                                                                                                                                                                                              \n[25] Let freedom ring from every hill and molehill in Mississippi.\\r\\nFrom every mountainside, let freedom ring.                                                                                                                                                                                                                                                                                                                                                                                       \n[26] And when this happens, when we allow freedom to ring, when we\\r\\nlet it ring from every village and hamlet, from every state and\\r\\nevery city, we will be able to speed up that day when all of\\r\\nGod's children, black men and white men, Jews and Gentiles,\\r\\nProtestants and Catholics, will be able to join hands and sing in\\r\\nthe words of the old Negro spiritual, \"Free at last! Free at\\r\\nlast! Thank God almighty, we're free at last!\"                                            \n\n\n\n# Turn all words to lower case\nwords.corpus <- tm_map(words.corpus, content_transformer(tolower))\n\n# Remove punctuations, numbers\nwords.corpus <- tm_map(words.corpus, removePunctuation)\nwords.corpus <- tm_map(words.corpus, removeNumbers)\n\n# How about stopwords, then uniform bag of words created\n\nwords.corpus <- tm_map(words.corpus, removeWords, stopwords(\"english\"))\n\n# Create Term Document Matrix\ntdm <- TermDocumentMatrix(words.corpus)\ninspect(tdm)\n\n<<TermDocumentMatrix (terms: 260, documents: 26)>>\nNon-/sparse entries: 383/6377\nSparsity           : 94%\nMaximal term length: 14\nWeighting          : term frequency (tf)\nSample             :\n         Docs\nTerms     16 18 19 2 20 26 3 6 8 9\n  able     1  0  3 0  0  2 0 0 0 0\n  day      2  1  1 0  0  1 0 0 0 0\n  dream    1  1  0 0  0  0 0 0 0 0\n  every    0  2  0 0  0  3 0 0 0 0\n  freedom  0  0  1 0  3  1 0 0 0 0\n  let      0  0  0 0  3  1 0 0 0 0\n  negro    0  0  0 1  0  1 2 0 0 1\n  one      2  1  1 0  0  0 2 0 0 0\n  ring     0  0  0 0  3  2 0 1 0 0\n  today    0  0  0 1  1  0 0 0 0 1\n\n\n\nm <- as.matrix(tdm)\nwordCounts <- rowSums(m)\nwordCounts <- sort(wordCounts, decreasing=TRUE)\nhead(wordCounts)\n\nfreedom     one    ring   dream     let     day \n     13      12      12      11      10       9 \n\n\n\n# Create Wordcloud\ncloudFrame<-data.frame(word=names(wordCounts),freq=wordCounts)\n\nset.seed(1234)\nwordcloud(cloudFrame$word,cloudFrame$freq)\n\n\n\n\n\nwordcloud(names(wordCounts),wordCounts, min.freq=1,random.order=FALSE, max.words=200,scale=c(4,.5), rot.per=0.35,colors=brewer.pal(8,\"Dark2\"))\n\n\n\n\n\n#  N-gram with two to three words\ntextstat_collocations(mlk, size = 2:3) \n\n            collocation count count_nested length      lambda           z\n1               will be    12           12      2  6.18006777  8.52344174\n2          freedom ring     9            9      2  6.16204416  7.86093251\n3                i have     8            8      2  5.79950409  7.72674740\n4                have a     9            9      2  5.30708831  7.60099495\n5            dream that     6            6      2  5.58442352  7.07713450\n6           let freedom     9            9      2  7.01188170  7.02799330\n7               one day     8            8      2  6.90192349  6.87515367\n8               a dream    10           10      2  6.25575004  6.75194436\n9              that one     5            5      2  5.10594547  6.58004714\n10            ring from     6            6      2  7.73858495  6.34302115\n11              we will     5            5      2  3.86081718  6.15370386\n12             negro is     4            4      2  4.65396035  6.11597271\n13           from every     4            4      2  5.11785291  5.94481579\n14              free at     3            3      2  7.12331459  5.59608371\n15            with this     3            3      2  4.53006624  5.45220051\n16             faith we     3            3      2  5.65068819  5.36947278\n17           this faith     3            3      2  5.65068819  5.36947278\n18             from the     7            7      2  3.08341547  5.30363525\n19             must not     2            2      2  5.42620788  5.20460024\n20             is still     3            3      2  5.37989735  5.19780340\n21           our nation     2            2      2  4.97170545  5.01431149\n22        hundred years     4            4      2  8.47324130  4.98413645\n23          years later     4            4      2  8.47324130  4.98413645\n24              we must     3            3      2  5.07381420  4.97383211\n25            the negro     6            6      2  3.68934326  4.86196261\n26              when we     2            2      2  4.65902686  4.81929021\n27              at last     3            3      2  8.22318001  4.78477488\n28              be able     7            7      2  7.12435112  4.76029764\n29          dream today     2            2      2  3.86677203  4.56840706\n30             with its     2            2      2  4.93219948  4.55360715\n31       god's children     2            2      2  7.88795934  4.50342390\n32           join hands     2            2      2  7.88795934  4.50342390\n33          for freedom     2            2      2  4.22651634  4.48456912\n34              came as     2            2      2  7.37588215  4.40694725\n35          one hundred     4            4      2  6.72982407  4.39835771\n36              able to     7            7      2  6.39243238  4.32365147\n37               in the     6            6      2  2.17334653  4.23621778\n38             shall be     2            2      2  4.50299743  4.22317970\n39               of our     4            4      2  3.05434175  4.19053424\n40               now is     3            3      2  6.47977386  4.17865188\n41              this is     2            2      2  3.31514248  4.14434519\n42                 as a     2            2      2  3.79901427  4.10034493\n43           every hill     2            2      2  6.58366067  4.09636748\n44      sweltering with     2            2      2  6.58366067  4.09636748\n45            you today     2            2      2  6.58366067  4.09636748\n46            have come     2            2      2  5.93072831  3.75354799\n47             of their     3            3      2  3.11909113  3.70546496\n48            and white     2            2      2  3.07448132  3.60774987\n49               by the     3            3      2  3.54339573  3.59126502\n50               is the     4            4      2  2.19722458  3.57802740\n51              time to     3            3      2  5.44370637  3.56663099\n52              be made     2            2      2  5.60288199  3.56485743\n53              down in     2            2      2  5.53491835  3.52478998\n54           in alabama     2            2      2  5.53491835  3.52478998\n55              to join     3            3      2  5.31969109  3.48898372\n56              a great     2            2      2  5.35416110  3.41693189\n57             boys and     2            2      2  5.30023860  3.38442936\n58             hill and     2            2      2  5.30023860  3.38442936\n59            later the     4            4      2  4.91465823  3.28099274\n60              come to     2            2      2  5.06556144  3.24149604\n61              of hope     2            2      2  3.27349691  3.13681123\n62               of new     2            2      2  3.27349691  3.13681123\n63       of brotherhood     3            3      2  4.73118685  3.11387202\n64               on the     2            2      2  3.18731502  3.05651338\n65          mountain of     2            2      2  2.76134150  3.04496971\n66             the time     3            3      2  4.62239955  3.04364353\n67              heat of     2            2      2  4.37343722  2.80997063\n68            of former     2            2      2  4.37343722  2.80997063\n69           of georgia     2            2      2  4.37343722  2.80997063\n70             of god's     2            2      2  4.37343722  2.80997063\n71       of segregation     2            2      2  4.37343722  2.80997063\n72              sons of     2            2      2  4.37343722  2.80997063\n73             words of     2            2      2  4.37343722  2.80997063\n74             with the     3            3      2  1.79939863  2.76173771\n75             the heat     2            2      2  4.26669595  2.74251867\n76           the mighty     2            2      2  4.26669595  2.74251867\n77             the sons     2            2      2  4.26669595  2.74251867\n78            the words     2            2      2  4.26669595  2.74251867\n79               all of     2            2      2  2.17088994  2.70389360\n80              and the     4            4      2  1.03334279  1.93104709\n81               to the     4            4      2  0.94890804  1.78367373\n82          the time to     3            0      3  3.26606636  1.13032087\n83             i have a     8            0      3  1.68160853  0.72439251\n84               of the     4            4      2  0.34188073  0.66310057\n85           be able to     7            0      3  1.70455087  0.59024096\n86         have come to     2            0      3  1.31957164  0.45161399\n87         all of god's     2            0      3  1.15936850  0.39431642\n88          is the time     3            0      3  0.95979188  0.36001531\n89           now is the     3            0      3  0.84580085  0.31720719\n90        with the heat     2            0      3  0.76999175  0.28684695\n91         the negro is     4            0      3  0.67536052  0.28260464\n92         have a dream     9            0      3  0.58984656  0.24426851\n93        of our nation     2            0      3  0.51082562  0.21746223\n94      with this faith     3            0      3  0.56734869  0.20916795\n95      years later the     4            0      3  0.57735438  0.19339014\n96        this faith we     3            0      3  0.38052616  0.14028450\n97           we will be     5            0      3  0.09967316  0.04495999\n98        faith we will     3            0      3 -0.07503519 -0.03083945\n99  sweltering with the     2            0      3 -0.23655401 -0.08710125\n100   of god's children     2            0      3 -0.28259670 -0.09369478\n101           came as a     2            0      3 -0.47356870 -0.15911139\n102      negro is still     3            0      3 -0.65642674 -0.26710716\n103         the heat of     2            0      3 -0.72619021 -0.28440540\n104         the sons of     2            0      3 -0.72619021 -0.28440540\n105        the words of     2            0      3 -0.72619021 -0.28440540\n106      sons of former     2            0      3 -1.04380405 -0.32331979\n107      dream that one     5            0      3 -0.85247922 -0.34520461\n108     from the mighty     2            0      3 -1.05164841 -0.40368538\n109   one hundred years     4            0      3 -1.25663553 -0.41832975\n110        a dream that     6            0      3 -1.38415532 -0.53242854\n111    let freedom ring     9            0      3 -1.60239563 -0.58922893\n112        that one day     5            0      3 -1.56115267 -0.63470415\n113   freedom ring from     5            0      3 -1.81950938 -0.71538178\n114     later the negro     3            0      3 -2.15475846 -0.90562482\n115       to join hands     2            0      3 -2.79512694 -0.92620311\n116        will be able     7            0      3 -2.54461097 -0.97862289\n117        free at last     3            0      3 -3.12717816 -1.00821968\n118      every hill and     2            0      3 -2.78472739 -1.01433624\n119       a dream today     2            0      3 -2.89970755 -1.11102196\n120       ring from the     3            0      3 -2.71402483 -1.11463644\n121 hundred years later     4            0      3 -3.97447602 -1.20437115\n122     ring from every     2            0      3 -4.04445379 -1.60411403\n123        able to join     2            0      3 -5.51680143 -2.04130446"
  },
  {
    "objectID": "posts/Assignment5_text-mining_word-cloud.html#example-2---winston-churchills-finest-hour-speech",
    "href": "posts/Assignment5_text-mining_word-cloud.html#example-2---winston-churchills-finest-hour-speech",
    "title": "Text Mining and Word Clouds - Assignment 5",
    "section": "Example 2 - Winston Churchill’s “Finest Hour” speech",
    "text": "Example 2 - Winston Churchill’s “Finest Hour” speech\n\n# load the speech text\nwc_speech <-URLencode(\"http://www.historyplace.com/speeches/churchill-hour.htm\")\n\n# use htmlTreeParse function to read and parse paragraphs\ndoc.html<- htmlTreeParse(wc_speech, useInternal=TRUE)\nwc <- unlist(xpathApply(doc.html, '//p', xmlValue))\nhead(wc, 3)\n\n[1] \"\"                                                                                                                                                                                                                                                                                                        \n[2] \"\"                                                                                                                                                                                                                                                                                                        \n[3] \"\\n        At 5:30 a.m. on May 10, 1940, Nazi Germany began a massive attack against\\n        Holland, Belgium, Luxembourg, and France. Defending those countries were\\n        soldiers of the British Expeditionary Force  along with the French, Belgian,\\n        and Dutch (Allied) armies. \\n      \"\n\nwords.vec <- VectorSource(wc)\n\n\n# Turn all words to lower case\nwords.corpus <- tm_map(words.corpus, content_transformer(tolower))\n# Remove punctuations, numbers\nwords.corpus <- tm_map(words.corpus, removePunctuation)\nwords.corpus <- tm_map(words.corpus, removeNumbers)\n# How about stopwords, then uniform bag of words created\nwords.corpus <- tm_map(words.corpus, removeWords, stopwords(\"english\"))\n\n\n# Create Term Document Matric\ntdm <- TermDocumentMatrix(words.corpus)\ninspect(tdm)\n\n<<TermDocumentMatrix (terms: 260, documents: 26)>>\nNon-/sparse entries: 383/6377\nSparsity           : 94%\nMaximal term length: 14\nWeighting          : term frequency (tf)\nSample             :\n         Docs\nTerms     16 18 19 2 20 26 3 6 8 9\n  able     1  0  3 0  0  2 0 0 0 0\n  day      2  1  1 0  0  1 0 0 0 0\n  dream    1  1  0 0  0  0 0 0 0 0\n  every    0  2  0 0  0  3 0 0 0 0\n  freedom  0  0  1 0  3  1 0 0 0 0\n  let      0  0  0 0  3  1 0 0 0 0\n  negro    0  0  0 1  0  1 2 0 0 1\n  one      2  1  1 0  0  0 2 0 0 0\n  ring     0  0  0 0  3  2 0 1 0 0\n  today    0  0  0 1  1  0 0 0 0 1\n\n\n\nm <- as.matrix(tdm)\nwordCounts <- rowSums(m)\nwordCounts <- sort(wordCounts, decreasing=TRUE)\nhead(wordCounts)\n\nfreedom     one    ring   dream     let     day \n     13      12      12      11      10       9 \n\n\n\n# Create Wordcloud\ncloudFrame<-data.frame(word=names(wordCounts),freq=wordCounts)\n\n\nset.seed(1234)\nwordcloud(cloudFrame$word,cloudFrame$freq)\n\n\n\nwordcloud(names(wordCounts),wordCounts, min.freq=1,random.order=FALSE, max.words=200,scale=c(4,.5), rot.per=0.35,colors=brewer.pal(8,\"Dark2\"))\n\n\n\n\n\n#  N-gram with two to three words\ncollocations <- textstat_collocations(wc, size = 2:3) \nhead(collocations, 20)\n\n     collocation count count_nested length   lambda         z\n1        we have    28           26      2 3.779163 13.838378\n2      air force     7            7      2 5.546500  9.802112\n3      in france    15           14      2 4.812919  9.490914\n4        will be     9            9      2 3.696220  8.975845\n5         of the    44           44      2 1.630720  8.798029\n6         in the    33           33      2 1.844981  8.517548\n7         a very     8            8      2 4.283527  8.517366\n8         do not     6            6      2 5.473433  8.491079\n9      have been     8            8      2 4.103849  8.387252\n10 history place     4            4      2 7.233114  8.065338\n11      would be     6            6      2 4.236184  8.063589\n12     there are     5            5      2 4.795077  8.052360\n13    very large     4            4      2 4.973497  7.886520\n14     before us     3            3      2 6.083149  7.595003\n15     they were     5            5      2 4.004477  7.542495\n16      last war     4            4      2 5.277759  7.530490\n17        it has     5            5      2 4.380001  7.496616\n18     every man     3            3      2 6.814746  7.436396\n19     those who     3            3      2 5.334751  7.365830\n20     any other     3            3      2 5.143222  7.228639"
  }
]